# 3 하드웨어와 운영체제
# 3.2 메모리 
무어의 법칙에 따라 트랜지스터의 개수가 급증 -> 클록 속도가 증가 -> 프로세스 속도 폭발적으로 증가
> 무어의 법칙  
> 마이크로칩 기술의 발전 속도에 관한 일종의 법칙으로 마이크로칩에 저장할 수 있는 데이터 분량이 18-24개월 마다 두 배씩 증가한다는 법칙이다.
> 이는 컴퓨터 성능이 거의 5년마다 10배, 10년마다 100배씩 개선된다는 것을 의미한다.
> 무어의 법칙은 PC의 처리속도와 메모리의 양이 2배로 증가하고 비용은 상대적으로 떨어지는 효과를 가져 왔다.
> 이러한 디지털 혁명은 1990년대 말 미국의 정보기술에 막대한 비용을 투자하는 계기를 만들기도 했다.
> 그러나, 2016년 2월에 반도체 업계가 경제성을 이유로 포기를 선언하면서 무어의 법칙이 폐기되게 되었다.


**하지만 프로세서의 속도 증가에 비해 메모리의 속도 증가는 미비 -> 프로세서 코어의 데이터 수요를 메인 메모리가 맞추기 어려워짐**

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/e964b0f3-8374-40a9-baf2-cc1ffcc74e7a)



## 3.2.1 메모리 캐시
이를 해결하기 위헤 고안된 것이 바로 CPU 캐시  
- CPU 캐시는 CPU에 있는 메모리 영역  
- 레지스터보다는 느리지만 메인 메모리보다는 훨씬 빠르다.
- 자주 액세스하는 메모리 위치는 사본을 떠서 CPU 캐시에 보관해 CPU가 메인 메모리를 재참조하지 않게 함
- 액세스 빈도가 높은 캐시일수록 프로세서 코어가 더 가까이 위치
  - L1: CPU와 가장 가까운 캐시, 전용 프라이빗 캐시
  - L2: L1 다음으로 가까운 캐시, 전용 프라이빗 캐시
  - L3: 일부 또는 전체 코어가 공유

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/b5cce693-9087-41f2-b666-b36168c79c92)
그림 3-1 다양한 메모리 종류별 액세스 시간

[그림 3-1]을 보면 L1~L3 캐시를 사용해 메인 메모리 액세스 시간과 비교했을 때 많이 빨라진 것을 볼 수 있다.

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/e09e25a6-3cb0-42e9-9abf-a2aa4eb4e007)
그림 3-2 전체 CPU 및 메모리 아키텍쳐

[그림 3-2]는 완성된 설계도이다.  
- CPU 코어마다 전용 L1, L2 캐시가 있고 모든 코어가 공유하는 L3 캐시가 있다.  
- 메인 메모리는 Northbridge 컴포넌트를 거쳐 액세스하고 이 버스를 관통함으로써 메인 메모리 액세스 시간을 단축

캐시를 도입해 프로세서 처리율은 현저히 개선되었지만 메모리에 있는 데이터를 **어떻게 캐시로 가져오고 캐시한 데이터를 어떻게 메모리에 다시 써야 할지** 결정해야 했다. -> **cache consistency protocol** 로 해결
> 병렬 처리 환경에서 이런 식으로 캐싱하면 또 다른 문제가 발생할 수 도 있다.

MESI 프로토콜
캐시 라인(64 bytes)에서 다음의 4가지 상태로 정의한다.
- Modified: 데이터가 수정된 상태
- Exclusive: 이 캐시에만 존재하고 main memory 내용과 동일한 상태
- Shared: 둘 이상의 캐시에 데이터가 들어 있고, 메모리 내용과 동일한 상태
- Invalid: 다른 프로세스가 데이터를 수정하여 무효한 상태

<img width="132" alt="image" src="https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/909e0834-9aed-4fe4-8edd-d676f228d1ea">

- write-through: 매번 캐시 연산 결과를 바로 메모리에 기록, 메모리 대역폭을 너무 많이 소모해 현재는 거의 안 씀
- write-back: 캐시 블록을 교체해도 프로세서가 변경된 캐시 블록만 메모리에 기록해 메인 메모리에 되돌아가는 트래픽을 감소시킴

캐시 기술 덕분에 데이터를 신속하게 메모리에서 읽고 쓸 수 있게 되었다.  특히 메모리 대역폭 측면에서 그 효과를 나타낼 수 있는데, 이론적으로 가능한 최대 전송률은 다음 인자에 따라 달라진다.

- 메모리 클록 주파수
- 메모리 버스 폭 (보통 64비트)
- 인터페이스 개수 (요즘 대부분 2개)

# 3.3 최신 프로세서의 특성
## 3.3.1 변환 색인 버퍼 (TLB)
TLB 정의
- 가상 메모리 주소를 물리적인 주소로 변환하는 속도를 높이기 위해 사용되는 캐시
- 최근에 일어난 가상 메모리 주소와 물리 주소의 변환 테이블 저장
- 일종의 주소 변환 캐시


TLB 발생 이유
- 모든 가상메모리 참조는 두 번의 물리 메모리 참조 수반        ( 해당 페이지테이블 항목 참조 / 요구된 데이터 접근 위한 참조)
- 두 배의 메모리 접근 시간을 갖게 됨


TLB 구성

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/dcd9971c-bdd9-43fb-90e6-e178776dfcec)

1) 가상주소가 주어지면, 처음에 TLB 살펴봄  
2-1) 가상주소가 TLB에 존재 (TLB hit) ---> 바로 프레임 번호 추출 --> 실주소 구성  
2-2) 해당 페이지테이블 항목 부재(TLB miss) ---> 페이지 번호로 페이지 테이블 인덱싱 ---> 페이지테이블 항목 참조  
3-1) 존재비트 1일 경우, 해당 페이지 주기억장치에 존재 ---> 페이지테이블 항목의 프레임 번호 이용 ---> 실주소 구성 및 TLB 갱신  
3-2) 존재비트 0일 경우, 해당 페이지 주기억장치에 존재X ---> 메모리 접근 오류 발생 (Page fault)

   
## 3.3.2 분기 예측과 추측 실행
프로레서가 조건 분기하는 기준값을 평가하느라 대기하는 현상 방지  
- 요즘 나온 프로레서는 다단계 명령 파이프라인을 이용해 CPU 1사이클도 여러 단계로 나누어 실행 -> 여러 명령이 동시 실행 중일 수도 있음
- 문제점: 조건문을 다 평가하기 전까지 분기 이후 다음 명령을 알 수 없으며 그 결과 분기문 뒤에 나오는 다단계 파이프라인을 비우는 동안 프로세서는 여러 사이클동안 멎게 된다.
- 트랜지스터를 활용해 가장 발생 가능성이 큰 브랜치를 미리 결정하는 휴리스틱을 형성 -> 추측이 맞으면 CPU는 다음 작업을 진행하고, 틀리면 부분적으로 실행한 명령을 모두 폐기 후 파이프라인 비움

## 3.3.3 하드웨어 메모리 모델
"어떻게 하면 서로 다른 여러 CPU가 일관되게 동일한 메모리 주소를 액세스할 수 있을까?"  
-> (하드웨어에 따라 다르겠지만) JIT 컴파일러인 javac와 CPU는 코드 실행 순서를 바꿀 수 있다.  
물론 코드 실행 순서를 바꿔도 현재 스레드가 바라보는 결과는 아무런 영향이 없다는 전제  

<img width="572" alt="image" src="https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/58900c60-3823-408d-a845-38d3dd32e85b">

JVM은 프로세서 타입별로 상이한 메모리 액세스 일관성을 고려하여 명시적으로 약한 모델로 설계됐다.  
따라서 멀티스레드 코드가 제대로 작동하게 하려면 락과 volatile을 정확히 알고 사용해야 한다.  

# 3.4 운영체제
OS의 주 임무는 여러 실행 프로세스가 공유한느 리소스 액세스를 관장하는 일

## 3.4.1 스케줄러

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/3ad24e24-2339-44b7-ba53-6fb2337dd76b)

- 프로세서 스케줄러는 CPU 액세스를 통제한다.
- 실행 큐라는 큐를 이용해 인터럽트에 응답하고 CPU 코어 액세스를 관리한다.
- 스케줄러의 움직임을 확인하는 가장 쉬운 방법은 OS가 스케줄링 과정에서 발생시킨 오버헤드를 관측하는 것

## 3.4.2 시간 문제
POSTIX 같은 업계 표준이 있어도 OS는 저마다 다르게 작동한다.  
ex) javaTimeMillis() 함수
OpenJDK에서 이 함수에는 실제로 작업을 수행하고 자바 System.currentTimeMillis()메서드의 반환값을 공급하는 OS에 특정한 호출이 있다. 
- BSD유닉스, 솔라리스, 리눅스, AIX의 구현코드는 모두 비슷하지만 유독 마이크로소프트 윈도우는 완전히 다르다.
- 윈도우는 유닉스 timeval 구조체 대신에 64비트 FiLETIME 구조체를 이용해 1601년 이후 경과한 시간을 100나노초 단위로 기록한다. 또한 물리 타이밍 하드웨어 따라 달라지는 시스템 클록의 '실 정확도'라는 개념이 있어 자바에서 타이밍 콜을 해도 그 작동 방식은 윈도우가 위치한 머신에 따라 달라진다.

## 3.4.3 컨텍스트 교환
컨텍스트 교환은 OS 스케줄러가 현재 실행 중인 스레드/테스크를 없애고 대기 중인 다른 스레드/태스크로 대체하는 프로세스로, 스레드 실행 명령과 스택 상태를 교체하는 모든 일에 연관되어 있다.  
유저 스레드 사이에 발생하든, 유저 모드에서 커널 모드로 바뀌면서 일어나든 컨텍스트 교환은 비싼 작업이다. (특히 후자)  

Context Switch가 발생하는 경우는 멀티태스킹, 인터럽트 핸들링, 사용자 모드와 커널 모드 간의 전환까지, 크게 3가지가 존재한다.

### 멀티태스킹(Multitasking)
실행 가능한 프로세스들이 운영체제의 스케줄러에 의해 조금씩 번갈아가며 수행되는 것을 말한다.
번갈아 가며 프로세스가 CPU를 할당 받는데 이때 Context Switching 한다.
사용자가 체감하기 힘든 속도로 Context Switching되며 프로세스가 처리되기 때문에 동시에 처리되는 것처럼 느껴진다.

### 인터럽트 핸들링(Interrupt handling)
인터럽트란 컴퓨터 시스템에서 예외 상황이 발생했을때 CPU에게 알려 처리할 수 있도록 하는 것을 말한다.
인터럽트가 발생하면 Context Switching한다.
I/O request : 입출력 요청
time slice expired : CPU 사용시간이 만료
fork a child : 자식 프로세스 생성
wait for an interrupt : 인터럽트 처리 대기

### 사용자와 커널 모드 전환(User and kernel mode switching)
사용자와 커널 모드 전환은 Context Switch가 필수는 아니지만 운영체제에 따라 발생할수 있다
Context Switching 과정

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/e112b282-403d-4cf3-83c0-282bd773a9d4)

Operating System Concepts
1. 요청 발생: 인터럽트 또는 트랩에 의한 요청이 발생.(트랩은 소프트웨어 인터럽트)
2. PCB에 저장: 운영체제는 현재 실행중인 프로세스(P0)의 정보를 PCB에 저장.
3. CPU 할당: 운영체제는 다음 프로세스(P1)의 정보를 PCB에서 가져와 CPU를 할당.

>  컨텍스트 스위칭은 성능저하의 원인이 될 수 있다?
> 
> 우리가 멀티 프로세스 대신 멀티 스레드로 프로그램 모델을 구성하는 이유는 프로세스의 컨텍스트 스위칭 오버헤드 보다 스레드의 컨텍스트 스위칭 오버헤드가 훨씬 작아 병목이 적기 때문이다. 하지만 어디까지나 프로세스에 비해 상대적으로 작다는 것이지 오버헤드 자체 비용은 결코 무시할수는 없다.즉, 싱글 스레드 모델에서는 스레드가 한개 이니 컨텍스트 스위칭 오버헤드가 발생되지 않지만, 멀티 스레드 모델은 스레드가 여러개이니 컨텍스트 스위칭 오버헤드가 발생하게 되고, 스레드가 많으면 많을 수록 스위칭 횟수도 많아지고 덩달아 오버헤드도 많아져 성능이 저하될 수 있다는 의미이다. 특히 싱글 코어와 같은 옛날 CPU와 같이 코어 수는 적은데 스레드 수를 계속 늘리게 되면, 각 코어에서 경합하는 스레드 수가 점점 많아질 거고, 어느 순간에는 오버헤드 때문에 성능 한계에 부딪히게 될 수 있게 된다.
>
> 이 컨텍스트 스위칭 때문에 스레드가 많을수록 성능이 좋다고 단언할 수 없다!!!

# 3.5 단순 시스템 모델
시스템 모델의 근본은 유닉스 계열 OS에서 작동하는 자바 애플리케이션의 단순한 개념으로, 다음 기본 컴포넌트로 구성된다.  
- 애플리케이션이 실행되는 하드웨어와 OS  
- 애플리케이션이 실행되는 JVM/컨테이너
- 애플리케이션 코드 자체
- 애플리케이션이 호출하는 외부 시스템
- 애플리케이션으로 유입되는 트래픽

이들 중 누구라도 성능 문제를 일으킬 수 있다.

# 3.6 기본 감지 전략
## 3.6.1 CPU 사용률
CPU 사용률은 애플리케이션 성능을 나타내는 핵심 지표이다.  
- 부하가 집중되는 도중에는 사용률이 가능한 한 100%에 가까워야 한다.

### vmstat
1. proc: 실행 가능한(r) 프로세스, 블록킹된(b) 프로세스 개수
2. memory: swap memory, 미사용(free) 메모리, 버퍼로 사용한 메모리 (buff), cache memory가 표시된다
3. swap: 디스크로 교체되어 들어간(swap-in) 메모리(si), disk에서 교체되어 빠져나온 메모리(swap-out) so 정보
최신 머신은 스왑이 많이 일어나지 않는다
4. io: block-in(bi), block-out(bo) 개수는 각각 블록(I/O) 장치에서 받은 512 bytes 블록, 블록 장치로 보낸 512 bytes 블록 개수이다
5. system: 인터럽트(in), 초당 context switch 횟수(cs)
6. cpu: cpu 직접 연관된 지표를 CPU 사용률 %로 표시한다.
  - us: 유저 시간
  - sy: 커널 시간(system time)
  - id: 유휴 시간
  - wa: 대기 시간
  - st: 도둑맞은 시간(vm에 할애된 시간)


## 3.6.2 가비지 수집
어떤 시스템에서 CPU 사용률이 아주 높게 나타난다면, GC는 대부분의 시간을 소비하는 주범이 아니다. -> GC 자체는 유저 공간의 CPU 사이클을 소비하되 커널 공간의 사용률에는 영향을 미치지 않는 활동이기 때문  
BUT, 어떤 JVM 프로세서가 유저 공간에서 CPU를 100% 사용하고 있다면 GC를 의심해야 한다. -> JVM에서 유저 공간의 CPU 사용률이 높은 건 거의 대부분 GC 서브시스템 탓이다.   
GC 로깅은 분석용 데이터의 원천으로서도 가치가 높기 때문에 JVM 프로세스는 예외 없이, 특히 운영 환경에서는 GC 로그를 꼭 남겨야 한다.  

## 3.6.3 입출력
- I/O는 다른 OS 파트처럼 분명하게 추상화되어있지 않았다.  
- 다행히 자바 프로개름은 대부분 단순한 I/O만 처리하며 I/O 서브시스템을 심하게 가동하는 애플리케이션 클래스도 비교적 적은 편
- CPU, 메모리 어느 한쪽과 I/O를 동시에 고갈시키는 애플리케이션은 거의 없다.
- 업무 체계가 잘 잡힌 운영 조직에서는 이미 I/O를 많이 쓰는 프로세스를 활발하게 모니터링하는 문화가 정착되어 있음
- 엔지니어는 애플리케이션에서 I/O가 어떻게 일어나는지 인지하는 것만으로도 충분하다.

### 커널 바이패스 I/O
커널을 이용해 데이터를 복사해 유저 공간에 넣는 작업이 상당히 비싼 경우도 있어 커널 대신 직접 네트워크 카드에서 유저가 접근 가능한 영역으로 데이터를 매핑하는 전용 하드웨어/소프트웨어를 쓴다.
-> 커널 공간과 유저 공간 사이를 넘나드는 행위 및 '이중 복사'를 막을 수 있다.  

자바는 기본적으로 이와 관련된 구현체를 제공하지 않으므로 필요한 기능을 구현하려면 커스텀 라이브러리를 써야 한다. 

## 3.6.4 기계 공감
성능을 조금이라도 쥐어짜내야 하는 상황에서 하드웨어를 폭넓게 이해하고 공감할 수 있는 능력이 무엇보다 중요하다는 생각  

ex) 두 스레드가 동일한 캐시 라인을 수정하려고 하면 실제로 경합이 발생   
- 첫 번째 스레드가 두 번째 스레드에 있는 캐시 라인을 무효화면 메모리에서 다시 읽어 들여야 함  
- 두 번째 스레드가 작업을 마치면 마찬가지로 첫 번째 스레드의 캐시 라인을 무효화
- -> 이렇게 주거니 받거니 하면서 false sharing을 하고 결국 성능 저하

**기계 공감 사상**에 따르면 먼저 이런 일이 발생할 수 있음을 이해하고 있어야 해결 방법을 찾을 수 있다.  
자바 객체는 필드 배치가 고정돼 있지 않기 대문에 캐시 라인을 공유한 변수를 쉽게 찾을 수 있다.
따라서 변수 주변에 패딩을 넣어 강제로 다른 캐시 라인으로 보내는 것도 한 가지 방법이다.

# 3.7 가상화
이미 실행 중인 다른 OS 위에서 OS 사본을 하나의 프로세스로 실행
가상화의 특징
- 가상화 OS에서 실행하는 프로그램은 비가상화 OS에서 실행할 때와 동일하게 작동해야 한다.
- 하이퍼바이저는 모든 하드웨어 리소스 액세스를 조정해야 한다.
- 가상화 오버헤드는 가급적 작아야 하며 실행 시간의 상당 부분을 차지해선 안된다.

## 가상화의 종류
### 호스트 OS 가상화

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/cce772fc-0f19-4c86-b520-e2b2f2a7fcca)

호스트OS형은 물리적 하드웨어위에 OS를 설치해, 그 위에 가상화 소프트웨어와 가상머신을 움직이는 방식이다.
즉, 물리 머신위에 직접동작하는 OS를 “Host OS”라한다.(일반 PC) 또한, 이 Host OS위에서 동작하는 가상화 머신에 설치된 O/S를 “Guest OS”라 부른다.

- 장점 : 가상의 하드웨어를 에뮬레이팅하기 때문에 호스트 운영체제에 크게 제약사항이 없음   
- 단점 : OS위에 OS가 얹히는 방식이기 때문에 오버헤드가 클 수 있음  

- VMware Workstation  
- Microsoft Virtual PC  
- VirtualBox  

### 하이퍼바이저 가상화

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/1c106385-e2f3-4f36-a1a8-c40dd227db68)

하이퍼바이저형은 Host OS없이 하드웨어에 하이퍼바이저를 설치하여 사용하는 가상화방식이다. 
하이퍼바이저라는 소프트웨어를 물리 하드웨어위에 직접움직여, 하이퍼바이져 위에 개개의 가상머신을 움직이게한다.
하이퍼바이저형의 특징은, 가상머신이 마치 독립한 호스트시스템과 같이 행동한다는 점 이다.
이는, 복수의 가상화머신이 서로 간섭하지 않도록 하는 것 이 하이퍼바이저형의 역할이다.
하이퍼바이저형은 호스트 OS와 별도로 개별 시스템처럼 행동하기때문에, 처리 오버헤드가 존재하지 않는다,
그로 인해 Host OS형 보다 더 퍼포먼스가 좋다는 메리트가 있다.
현재 서버 가상화 기술에서는 주류 방식으로 사용되고있다.

- 장점 : 별도의 Host OS가 없기 때문에 오버헤드가 적고, 하드웨어를 직접 제어하기 때문에 효율적으로 리소스를 사용할 수 있음  
- 단점 : 자체적으로 머신에 대한 관리 기능이 없기 때문에 관리를 위한 컴퓨터나 콘솔(CLI)이 필요함

- VMware ESX Server (전가상화)  
- MS Hyper-v (전가상화)  
- Citrix XenServer (반가상화)

### 전가상화 vs 반가상화?
### 전가상화

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/7751309e-4a6b-4cc5-8e0d-1778a79d3798)

전가상화는 하드웨어를 완전히 가상화 하는 방식으로 Hardware Virtual Machine 이라고도 불립니다.
하이퍼바이저 관리용 가상 머신이 실행되며, 모든 가상머신들의 하드웨어 접근이 해당 관리 머신을 통해서 이루어집니다.
GuestOS는 하이퍼바이저의 존재를 알 필요가 없습니다.
- 장점: 하드웨어를 완전히 가상화 하기 때문에 Guest OS의 커널 등의 수정이 필요 없습니다. 특히 Windows부터 Linux까지 다양한 OS를 사용할 수 있는 장점이 있습니다
- 단점: 하이퍼바이저의 관리용 가상 머신이 모든 명령을 중재하고 번역하기 때문에 비교적 성능이 느릴 수 있습니다.

### 반가상화

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/b9e5486f-decb-4ba8-8f77-97bdee673e94)

- 반가상화는 전가상화와 유사한 부분이 많지만 Guest OS는 스스로가 가상 환경임을 인지하고 있습니다.
- 전가상화의 성능 저하 문제점을 개선하기 위해 별도의 인터페이스를 통해 명령을 하게 됩니다.
- 위와 같은 명령을 하기 위해선 Guest OS의 일부를 수정해줘야 하는 단점이 있습니다.


### 컨테이너 가상화

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/8ace74c8-d080-4bb1-8cfe-149afd59ab77)

호스트 OS위에 컨테이너관리 소프트웨어를 설치하여, 논리적으로 컨테이너를 나누어 사용한다.
컨테이너형의 컨테이너에는 게스트OS나 가상하드웨어를 포함하지 않고 어플리케이션 동작을 위한 라이브러리와 어플리케이션등으로 구성되기 때문에 이를 각각 개별 서버처럼 사용가능하다.
컨테이너형 에서는 일반적으로 가상화소프트웨어를 “컨테이너엔진” 혹은 “컨테이너관리 소프트웨어”라고도 부른다.

- 장점 : 컨테이너 가상화는 오버헤드가 적어 가볍고 빠른 장점이 있음

- OpenVZ
- LXC
- Linux VServer
- Docker
- Oracle Solaris Zones

# 3.8 JVM과 운영체제
JVM은 자바 코드에 공용 인터페이스를 제겅화여 OS에 독립적인 휴대용 실행 환경을 제공한다. BUT 스레드 스케줄링같은 아주 기본적인 서비스조차도 하부 OS에 반드시 액세스해야 한다.  
이런 기능은 native 키워드를 붙인 네이티브 메서드로 구현한다. 
- C 언어로 작성되어 있다
- Java Native Interface(JNI) 라 한다.

```java
public final native Class <?> getClass();
public native int hashCode();
protected native Object clone() throws CloneNotSupportedException;
public final native void notify();
public final native void notifyAll();
public final native void wait(long timeoutMillis) throws InterruptedException;
```
os::javaTimeMillis() 함수는 자바 정적 메서드 System.currentTimeMillis()에 구현된 로직을 처리한다.  
자바에서는 C코드 브릿지를 통해 액세스할 수 있다.

핫스팟에서는 이 코드가 어떻게 호출이 될까?  

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/86006389/1d68daa1-5c86-4c36-835d-0f082fe65fa9)

1. System.currentTimeMillies() 는 JVM_CurrentTimeMillis() 라는 JVM 엔트리 포인트 메서드에 매핑된다.
2. JVM_CurrentTimeMillis()는 VM 진입점에 해당하는 메서드를 호출한다.
-> 결국 OpenJDK 매크로 2개로 감싼 os::javaTimeMillis()를 호출하는 구조
