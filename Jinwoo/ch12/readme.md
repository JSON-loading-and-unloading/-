## 동시 성능 기법

최신 하드웨어를 오롯이 활용하려면 자바 개발자는 최소한 동시성(concurrency)란 무엇인지, 그것이 애플리케이션 성능에 끼치는 영향은 무엇인지 최소한의 배경지식은 가지고 있어야 한다.

## 12.1 병렬성이란?

요즘의 **멀티코어** 세상에서는 **암달의 법칙**이 연산 태스크의 실행 속도를 향상시키는 핵심 요소이다.

### 암달의 법칙

* 연산 태스크는 '병렬 실행이 가능한 파트'와 '반드시 순차 실행해야 하는 파트'로 구성된다.
* S : 순차 실행 파트
* T : 총 태스크 소요 시간
* N : 프로세서 개수
* 전체 태스트 소요시간 T(N) = S + (1/N) * (T-S)
* 위의 수식은 프로세서를 무한히 증가시켜도 총 소요 시간은 순차 작업 시간 이상 줄일 수 없다는 것을 의미한다. 더 빠른 코어를 장착하여 싱글 스레드 성능을 개선하면 S값을 줄일 수 있겠지만, 최신 하드웨어는 CPU 클록 스피드를 높여도 그만한 속도 향상을 체감하기 어렵다.

암달의 법칙에 따르면, 병렬 태스크나 다른 순차 태스크 간에 소통할 필요가 전혀 없을 경우 이론적으로 속도는 무한히 높일 수 있다.

보통은 데이터 공유 없이 워크로드를 나누어 여러 워커 스레드에 분산시킨다. 그리고 스레드끼리 상태나 데이터를 공유하기 시작하면 워크로드가 점차 복잡해지면서 일부 태스크를 순차 처리하게 되고, 통신 오버헤드가 발생한다.

상태를 공유하는 워크로드는 무조건 정교한 보호/제어 장치가 필요하다. 자바에서는 **JMM**이라는 메모리 보증 세트를 제공한다.

### 12.1.1 자바 동시성 기초

다음과 같이 카운터를 증가시키는 코드는 개별적인 한 과정으로 수행될까?

```
public class Counter {
    private int i = 0;

    public int increment() {
        return i = i + 1;
    }
}
```

카운터를 락으로 적절히 보호하지 않은 상태로 멀티스레드 환경에서 이 코드를 실행하면, 다른 스레드에 의해 결과값이 소실되어 예상했던 결과가 나오지 않을 수 있다.

OS 스케줄러는 때를 가리지 않고 스레드를 컨텍스트 교환하므로, 스레드가 둘 뿐인 상황에서도 바이트코드는 다양한 순서로 실행될 수 있다.

변수값을 cache가 아니라 main memory에서 가저오도록 하는 ```volatile```을 추가한다고 해서 문제가 해결되지 않는다. 증분 연산자의 복잡한 특성 탓에 방금 전 업데이트 소실 문제를 막을 수 없다.

다음은 두 스레드가 동일한 카운터의 레퍼런스를 공유하는 코드이다.

```
public class CounterExample implements Runnable {

    private final Counter counter;

    public CounterExample(Counter counter) {
        this.counter = counter;
    }

    @Override
    public void run() {
        for (int i=0; i<100; i++ ) {
            System.out.println(Thread.currentThread().getName() + "Value: " + counter.increment());
        }
    }
}
```

카운터가 무방비로 노출되어 있어 프로그램을 돌릴때마다 두 스레드는 갖가지 형태로 서로 엮일 가능성이 크다. 이 문제는 ```synchronized```로 감싸서 int 같은 단순 값의 업데이트를 제어하면 해결할 수 있다.

```synchronized```를 사용하면 동기화처리가 되지만 너무 남발하면 오히려 프로그램 성능 저하를 일으킬 수 있다. 처리율 향상은 동싱성을 부여하는 전체 목표와 상충된다. 따라서 코드 베이스를 병렬화하는 작업을 진행할 때에는 복잡도가 늘어난 대가로 얻은 혜택을 충분히 입증할 수 있도록 성능 테스트가 수반되어야 한다.

## 12.2 JMM의 이해 

JMM은 다음 질문에 답을 찾는 모델이다.

* 두 코어가 같은 데이터를 액세스하면 어떻게 되는가?
* 언제 두 코어가 같은 데이터를 바라본다고 장담할 수 있는가?
* 메모리 캐시는 위 두 질문의 답에 어떤 영향을 미치는가?

자바 플랫폼은 공유 상태를 어디선 액세스하던 '순서에 관한 보장' 그리고 '여러 스레드에 대한 업데이트 가시성 보장' 이 2가지 내용을 반드시 이행한다.

싱글코어에서 멀티코어로, 그리고 코어가 늘어날수록 메모리 모델이 중요해지고 있다.

고수준에서 JMM 같은 메모리 모델은 2가지 방식으로 접근한다.

* 강한 메모리 모델
    * 전체 코어가 항상 같은 값을 바라본다.

* 약한 메모리 모델
    * 코어마다 다른 값을 바라볼 수 있고 그 시점을 제어하는 특별한 캐시 규칙이 있다. 

프로그래머 입장에서는 강한 메모리 모델이 끌린다. 하지만 최신 멀티 CPU 시스템에는 맞지 않다. 또한 자바의 특성상 JVM이 강한 메모리 모델 기반으로 설계되었다면 약한 하드웨어 상에서 JVM을 구현하려면 엄청난 이식 작업이 수반되어야 한다.

JMM은 아주 약한 메모리 모델이고, 다음 기본 개념을 기반으로 애플리케이션을 보호한다.

* Happens-Before(~보다 먼저 발생)
    * 한 이벤트는 무조건 다른 이벤트보다 먼저 발생한다.

* Synchronizes-With(~와 동기화)
    * 이벤트가 객체 뷰를 메인 메모리와 동기화시킨다.

* As-If-Serial(순차적인 것처럼)
    * 실행 스레드 밖에서는 명령어가 순차 실행되는 것처럼 보인다.

* Release-Before-Acquire(획득하기 전에 해제)
    * 한 스레드에 걸린 락을 다른 스레드가 그 락을 획득하기 전에 해제한다.

자바에서 스레드는 객체 상태 정보를 스스로 들고 다니며, 스레드가 변경한 내용은 메인 메모리로 곧장 반영되고 같은 데이터를 액세스하는 다른 스레드가 다시 읽는 구조이다. JVM에는 저수준 메모리 액세스를 감싸놓은 구현 코드가 상당히 많다.

## 12.3 동시성 라이브러리 구축

java.util.concurrent 패키지는 멀티스레드 애플리케이션을 자바로 더 쉽게 개발할 수 있게 세심하게 설계된 라이브러리이다. 이 라이브러리를 구성하는 핵심 요소는 몇 가지 일반 카테고리로 분류된다.

* 락, 세마포어
* 아토믹스
* 블로킹 큐
* 래치
* 실행자

일부 라이브러리(락, 아토믹스)는 비교해서 바꾸기(CAS) 기법을 구현하기 위해 저수준 프로세서 명령어 및 OS별 특성을 활용한다.

CAS는 '예상되는 현재 값'과 '원하는 새 값', 그리고 메모리 위치를 전달받아 다음 2가지 일을 하는 아토믹 유닛이다.
1. 예상되는 현재 값을 메모리 위치에 있는 콘텐츠와 비교한다.
2. 두 값이 일치하면 현재 값을 원하는 새 값으로 교체한다.

CAS는 여러 가지 중요한 고수준의 동시성 기능을 구성하는 기본 요소이다. CAS는 구현체별 확장 기능이라고 볼 수 있으므로 CAS 하드웨어는 sun.misc.Unsafe 클래스를 통해 액세스한다.

### 12.3.1 Unsafe

Unsafe는 공식적으로 지원하지 않는 내부 API이지만, 거의 모든 주요 프레임워크의 구현 핵심부를 차지하게 됐다. 다음은 Unsafe로 할 수 있는 일이다.

* 객체는 할당하지만 생성자는 실행하지 않는다.
* 원메모리에 액세스하고 포인터 수준의 연산을 수행한다.
* 프로세서별 하드웨어 특성을 이용한다.

따라서 다음과 같은 고수준의 프레임워크 기능을 구현할 수 있다.

* 신속한 (역)직렬화
* thread-safe 네이티브 메모리 액세스
* 아토믹 메모리 연산
* 효율적인 객체/메모리 레이아웃
* 커스텀 메모리 펜스
* 네이티브 코드와의 신속한 상호작용
* JNI에 관한 다중 운영체제 대체물
* 배열 원소에 volatile하게 액세스

다음은 자바 5에서 도입된 아토믹 클래스와 함께 CAS가 실제로 작동하는 모습이다.

### 12.3.2 아토믹스와 CAS

아토믹 변수는 volatile 확장판이라고 할 수 있지만, volatile보다 더 유연해서 상태 의존적 업데이트를 안전하게 수행할 수 있다. 

아토믹스를 효과적으로 활용하려면 주어진 기능 외에 임의로 코드를 구현해서 섞어 쓰지 말아야 한다.

### 12.3.3 락과 스핀락

* 스핀락 : 다른 스레드가 lock을 소유하고 있는 상황이라면 lock이 반환될 때까지 계속 확인하며 대기하는 것을 말한다.

최신 시스템은 대부분 하드웨어가 지원하리라 가정하고 CAS로 스핀락을 구현한다. 스핀락은 CPU마다 조금씩 다르지만 핵심 개념은 동일하다.
* '테스트하고 세팅'하는 작업은 반드시 아토믹해야 한다.
* 스핀락에 경합이 발생하면 대기 중인 프로세서는 빽빽한 루프를 실행하게 된다.

## 12.4 동시 라이브러리 정리

지금까지 아토믹 클래스와 단순 락을 구현하는 데 사용하는 저수준 기법을 정리했다. 표준 라이브러리에서는 이런 기능을 어떻게 활용해 완전한 범용 라이브러리를 구축하는지 알아보자.

### 12.4.1 java.util.concurrent

자바 5부터 전면 개편되어 좀 더 일반화한 락 인터페이스가 java.util.concurrent.locks.Lock에 추가되었다.

**ReentrantLock**은 Lock의 주요 구현체로, 내부적으로는 int값으로 compareAndSwap() 을 한다. 즉 경합이 없을 때는 락을 획득하는 과정이 락-프리하다. 따라서 락 경합이 별로 없는 시스템에서는 성능이 매우 좋아지고 다양한 락킹 정책을 적용 가능한 유연성도 얻게 된다.

compareAndSwap() 을 호출하고 Unsafe를 사용한 코드는 AbstractQueued Synchronizer를 확장한 정적 서브클래스 Sync에 있다. 또한 AbstractQueued Synchronizer는 스레드를 파킹 및 재개하는 메서드가 구현된 LockSupport 클래스를 활용한다.

LockSupport 클래스는 스레드에게 퍼밋이라고 하는 허가증을 발급하는데 오직 한 가지 퍼밋만 발급할 수 있고 발급할 퍼밋이 없으면 스레드는 기다려야 한다.

### 12.4.2 읽기/쓰기 락

기존 syncrhonized나 ReentrantLock을 이용하면 한 가지 락 정책을 따를 수 밖에 없다. 여러 읽기 스레드가 하나의 쓰기 스레드에 달려드는 상황에서는 어느 한 읽기 스레드 때문에 나머지 읽기 스레드를 블로킹하느라 불필요한 시간을 허비할 가능성이 있다.

ReentrantReadWriteLock 클래스의 ReadLock과 WriteLock을 활용하면 여러 스레드가 읽기 작업을 하는 도중에도 다른 읽기 스레드를 블로킹하지 않게 할 수 있다. 이렇게 구현하면 단일 락을 사용했을 때보다 성능이 현저히 향상된다. 

### 12.4.3 세마포어

세마포어는 '최대 O개 객체까지만 액세스를 허용한다.'는 전제하에 정해진 수량의 퍼밋으로 액세스를 제어한다.

Semaphore 클래스의 acquire() 메서드는 사용 가능한 퍼밋 수를 하나씩 줄이는데, 더 이상 쓸 수 있는 퍼밋이 없을 경우 블로킹한다. release() 메서드는 퍼밋을 반납하고 대기 중인 스레드 중 하나에게 해제한 퍼밋을 전달한다.

세마포어를 사용하면 리소스가 블로킹되거나 리소스를 기다리는 큐가 형성될 가능성이 커서 스레드 고갈을 막기 위해 처음부터 **공정모드**로 초기화하는 경우가 많다.

### 12.4.4 동시 컬렉션

### ConcurrentHashMap

버킷 또는 세그먼트로 분할된 구조를 최대한 활용하여 실질적인 성능 개선 효과를 얻는다. 각 세그먼트 자체 락킹 정책을 가질 수 있어 필요할 경우에 어느 한 세그먼트만 락을 거는 행위도 가능하다. 

### Iterator

일종의 스냅샷으로 획득하기 때문에 ConcurrentModificationException이 발생할 일이 거의 없다.

### CopyOnWriteArrayList, CopyOnWriteArraySet

두 클래스에서 자료 구조를 변경하면 배킹 배열 사본이 하나 더 생성된다. 덕분에 기존 이터레이터는 예전 배열을 계속 탐색할 수 있고, 레퍼런스가 하나도 없으면 이 배열 사본은 가비지 수집 대상이 된다. 이렇게 스냅샷 스타일로 이터레이션하므로 ConcurrentModiFicationException이 일어날 가능성이 없다.

### 12.4.5 래치와 베리어

스레드 세트의 실행을 제어하는 유용한 기법이다. 시스템이 그냥 전체 스레드를 실행하면 이벤트 순서를 보장할 수 없다. 모든 스레드가 태스크#1 -> 태스크 #2 -> 태스트 #3 순서로 진행되는 것이 이상적이라면 래치를 쓸 수 있다.

* 래치는 단 한번밖에 사용할 수 없다.
* 래치는 애플리케이션을 처음 시작하거나 멀티스레드를 테스트하는 도중, 캐시 적재 등의 작업을 할 때 아주 유용하다. 

## 12.5 실행자와 태스크 추상화

스레딩 문제가 거의 없는 추상화 수준은 동시 태스크, 즉 현재 실행 컨텍스트 내에서 동시 실행해야 할 코드나 작업 단위로 기술할 수 있다. 일의 단위를 태스크로 바라보면 동시 프로그래밍을 단순화할 수 있다.

### 12.5.1 비동기 실행이란 ?

자바에서 태스크를 추상화하는 방법은 값을 반환하는 태스크를 Callable 인터페이스로 나타내는 것이다.

얼핏보면 Callabe은 Runnable과 비슷하나, Runnable은 결과를 반환하거나 예외를 던지지 않는다.

ExecutorService는 관리되는 스레드 풀에서 태스크 실행 메커니즘을 규정한 인터페이스이다. 풀에 담긴 스레드를 어떻게 관리하고, 그 개수는 몇개까지 둘지, 이 인터페이스를 실제로 구현한 코드가 정의한다. ExecutorService는 submit() 메서드를 통해 Runnable 또는 Callable 객체를 받는다.

Executors는 헬퍼 클래스로 new*팩토리 메서드로 실행자 메서드를 생성한다.

일단 태스크가 제출되면 비동기로 처리되며, 태스크를 제출한 코드는 스스로를 블로킹할지, 결과를 폴링할지 선택할 수 있다.

### 12.5.2 ExecutorService 선택하기

올바른 ExecutorService를 선택하면 비동기 프로세스를 적절히 잘 제어할 수 있고, 풀 스레드 개수를 정확히 잘 정하면 성능이 뚜렷이 향상될 수 있다.

전체 애플리케이션 설정에 따라 ExecutorService를 경험적으로 튜닝해야 할 경우도 있다. 이때 흔히 사용하는 지표는 코어 수 대비 풀 스레드 수이다. 동시 실행 스레드 개수를 프로세서 개수보다 높게 잡으면 경합이 발생한다. 경합이 어느 한계치에 이르면 동시 처리 모드로 전환하더라도 성능 효과는 반감될 수 있기 때문에 성능 모델을 올바르게 정립하고 성능 향상 정도를 측정할 수 있는 역량을 갖추는 일이 시급하다.

### 12.5.3 포크/조인

ForkJoinPool 클래스는 관리되는 스레드 풀을 제공하며, 다음과 같은 두 가지 특성이 있다.

* 하위 분할 태스크를 효율적으로 처리할 수 있다.
* 작업 빼앗기 알고리즘을 구현한다.

하위 분할 태스크는 표준 자바 스레드보다 가벼운, 스레드와 비슷한 엔티티이다. ForkJoinPool 실행자에서 적은 수의 실제 스레드가 아주 많은 태스크/서브태스크를 담당해야 하는 유스케이스에 주로 사용한다.

작업 뺴앗기 알고리즘은 예를 들어, 어느 스레드가 자신이 할당받은 작업을 모두 마쳤는데 다른 스레드에 일이 남아있으면 큐에서 작업을 몰래 가져와 실행하는 방식이다. 여러 스레드가 수행 중인 작업량의 균현을 다시 맞추는 건 간단하지만 효과가 좋은 영리한 발상이다.

## 12.6 최신 자바 동시성

현대 자바는 언어 및 표준 라이브러리에 내장된 추상화를 이용해 성능을 크게 높일 수 있는 환경을 제공하여 동시 프로그래밍의 강점을 살릴 수 있게 한다. 

### 12.6.1 스트림과 병렬 스트림

Collection 인터페이스의 parallelStream()을 이용하면 병렬로 데이터를 작업 후 결과를 재조합할 수 있다. 이 메서드를 호출하면 내부적으로 Spliterator를 써서 작업을 분할하고 공용 포크/조인 풀에서 연산을 수행한다. 까다로운 병렬 문제를 다룰 때 편리하지만 태스크를 여러 곳에 분배해 재조합하는 비용이 들기 때문에 신중하게 사용해야 한다. 실제로 컬렉션이 작을수록 직렬 연산이 병렬 연산보다 훨씬 빠르다. 

### 12.6.2 락-프리 기법

락-프리 기법은 블로킹이 처리율에 악영향을 미치고 성능을 저하시킬 수 있다는 전제하에 시작한다. 중단/재개 시키는 과정에서 많은 시간이 소요될 수 있기에 락-프리한 기법보다 훨씬 느리다.

락-프리 기법은 CPU 코더를 계속 스피닝하여 컨텍스트 교환없이 즉시 해당 코어에서 작업할 준비를 한다는 뜻이다.

락-프리 기법 역시 대가가 따른다. CPU 코어를 차지하면서 사용률, 전력 소비 측면에서 비용이 든다.

