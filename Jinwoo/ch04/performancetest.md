## 4.1 성능 테스트 유형
테스트로 확인하고 싶은 정량적 질문 리스트와 그 테스트가 대상 애플리케이션 입장에서 중요한 이유를 간단히 적어 성능 테스트를 기획하자.

일반적인 성능 테스트

### 4.1.1 지연 테스트
* 지연 : 하나의 트랜잭션을 처리하고 그 결과를 반대편 끝에서 바라볼 때까지 소요된 시간(종단시간)
> '고객이 트랜잭션(또는 페이지 로딩)을 얼마나 오래 참고 기다려야 하는지' 측정하는 테스트
* 종단 트랜잭션에 걸리는 시간은 ?
* 목적 : 유저 경험을 직접 개선하거나 서비스 수준 협약서 조항을 이행하는 것

### 4.1.2 처리율 테스트
* 처리율 : 시스템이 수행 가능한 작업 비율을 나타낸 지표
> 지연을 모니터링하면서 테스트한다. 이때 지연 분포가 변하는 시점, 즉 한계점이 바로 '최대 처리율'이다.
* 현재 시스템이 처리 가능한 동시 트랜잭션 개수는 ?
* 목표 : 시스템 성능이 급락하기 전, '최대 처리율' 수치를 측정하는 것

### 4.1.3 부하 테스트
> 임계치 한계에 도달 할 때까지 시스템의 부하를 지속적으로 지속적으로 증가시켜 시스템을 테스트하는 것
* 특정 부하를 시스템이 감당할 수 있는가 ?
* 신규 고객을 유치하거나 새로운 시장에 진출하기 전, 애플리케이션 트래픽이 상당할 것으로 예상되는 특정 비즈니스 이벤트, 예를 들어 광고 캠페인, 바이럴 콘텐츠, 에 대비하기 위한 부하테스트를 수행할 수 있다.

### 4.1.4 스트레스 테스트
> 시스템 여력이 어느 정도인지 알아보는 수단이다.
* 이 시스템의 한계점은 어디까지인가 ?

### 4.1.5 내구 테스트
> 평균 또는 그보다 높은 사용률로 시스템에 일정 부하를 계속 주며 모니터링하다가 갑자기 리소스가 고갈되거나 시스템이 깨지는 지점을 찾는다.
* 시스템을 장시간 실행할 경우 성능 이상 증상이 나타나는가 ?
* 빠른 응답을 요구하는 시스템에서 많이 한다.

### 4.1.6 용량 계획 테스트
* 스트레스 테스트 : 현재 시스템이 어느 정도 부하를 버틸 수 있는지 알아보는 것
> '업그레이드'한 시스템이 어느 정도 부하를 감당할 수 있을지 미리 내다보는 것

### 4.1.7 저하 테스트

* 저하 : 지연이 증가하는 양상
> 복원 테스트 하나만 생각하면 된다. 기본적으로 평상시 운영 환경과 동등한 수준의 부하를 시스템에 가하는 도중, 어떤 컴포넌트나 전체 서브시스템이 갑자기 능력을 상실하는 시점에 벌어지는 일들을 확인한다.
* 대표적인 하위 유형으로는 카오스 멍키가 있다.\
    : 복원성 있는 아키텍처에서는 어느 한 컴포넌트가 잘못되어도 다른 컴포넌트까지 연쇄적으로 무너뜨리면서 전체 시스템에 부정적 영향을 끼치지 않는다.

## 4.2 기본 베스트 프랙티스

성능 튜닝시 기본 3가지 원칙에 따라 결정한다.
* 나의 관심사가 무엇인지 식별하고 그 측정 방법을 고민한다.
* 최적화하기 용이한 부분이 아니라, 중요한 부분을 최적화한다.
* 중요한 관심사를 먼저 다룬다.

### 4.2.1 하향식 성능
> 전체 애플리케이션의 성능 양상부터 먼저 알아보는 접근 방식이다.

* 성과를 극대화하기 위해서는 먼저 테스트팀이 테스트 환경을 구축한 다음, 무엇을 측정하고 무엇을 최적화해야 하는지, 또 성능 활동을 전체 소프트웨어 개발 주기에서 어떻게 병행해야 하는지, 전 팀원이 명확하게 이해해야 한다.

### 4.2.2 테스트 환경 구축

* 테스트 환경 구축은 테스트 팀이 가장 먼저해야하는 일이며, 테스트 환경은 가급적 모든 면에서 운영 환경과 똑같아야 한다. 
    * 애플리케이션 서버, 웹 서버, DB, 로드 밸런서, 네트워크 방화벽 등도 맞추어야 한다.
    * 운용 중인 각종 서비스도 목업 형태로 반영돼야 한다.
* 운영 환경이 반영되지 않은 QA 환경에서 성능 테스트하는 것은 리스크가 매우 크다.

### 4.2.3 성능 요건 식별

* 전체 시스템 성능은 애플리케이션 코드뿐만 아니라 컨테이너, OS, 하드웨어 모두 나름대로 영향을 끼친다.
* 성능을 평가하는 지표는 코드 관점에서만 생각해서도 안 되고, 시스템을 전체적으로 바라보며 고객과 경영진에게 중요한 측정값을 고려해야 한다.
* 성능 비기능 요건 (NFR) : 최적화하려는 핵심 지표
    * 응답 시간 : 평균 응답 시간을 30% 줄인다.
    * 처리율 : 기존 하드웨어 처리율을 5배 높일 수 있게 시스템을 개선한다.

### 4.2.4 자바의 특정 이슈
* JVM에는 성능 엔지니어가 잘 이해하고 주의 깊게 살펴야 할 복잡한 부분들이 있다.
* 특히 JIT 컴파일은 중요한 부분이라서 유심히 살펴야 한다.
* 성능과 관려해서 어떤 메서드가 컴파일 중인지 로그를 남겨 살피고 핵심 코드 경로상의 중요 메서드가 잘 컴파일되고 있는지 확인하는 것이 중요하다.
    * JVM은 어떤 메서드를 JIT 컴파일해서 최적화한 기계어로 변환할지 분석한다.
    * JIT 컴파일 안하기로 결정된 메서드
        1. 자주 실행되는 메서드가 아니다.
        2. 메서드가 너무 크고 복잡해서 컴파일 분석을 할 수 없다.

### 4.2.5 SDLC 일부로 성능 테스트 수행하기
* 성능 테스트를 필요할때만 하는 것이 아니라, 전체 SDLC(소프트웨어 개발 수명주기)의 일부로 수행해야 한다.

## 4.3 성능 안티패턴 개요
안티패턴은 소프트웨어의 좋지 않는 패턴이다. 이러한 잘못된 패턴을 분류하고 유형화함을 통해서 팀원들이 서로 소통하고, 안티패턴을 제거할 수 있도록 패턴 언어(pattern language)를 개발한다.

이러한 잘못된 패턴들이 생기는 이유는 5개로 분류할 수 있다.

### 4.3.1 지루함
지루하다고 맞지 않는 기술을 억지로 끼워넣는 경우가 존재한다. 일례로 Collections.sort() 한 줄이면 될 것을 직접 정렬 알고리즘을 구현해 필요 이상으로 복잡하게 코딩을 하거나, 지금껏 알려지지 않은 기술로 컴포넌트를 제작하기도 한다.

### 4.3.2 이력서 부풀리기
자신의 이력서를 부풀리기 위해 프로젝트에 불필요한 기술을 덧붙일 수 있다. 개발자의 지루함, 이력서 부풀리기 탓에 불필요한 기술을 덧댄 결과, 개발자가 이직한 후에도 아주 오랜 기간동안 시스템에 지대한 영향을 끼치게 된다.

### 4.3.3 또래 압박
팀원들이 기술을 결정할 때 관심사를 분명히 밝히지 않고 충분희 논의 없이 진행하는 경우에도 발생할 수 있다.

### 4.3.3 이해 부족
지금 사용하는 툴의 기능도 온전히 모르는데, 새로운 툴로 문제를 해결하는 경우가 있다. 하지만 이런 것은 기술복잡도를 높이기 때문에 복잡도를 높익는 것과 현재 툴 사이의 균형을 맞추는 것이 중요하다.

### 4.3.4 오해와 있지도 않은 문제
문제 자체가 무엇인지 제대로 이해하지 못한 채 오로지 기술을 이용해 문제를 해결하는 상황

<br>

$ \rightarrow $ 이러한 안티패턴을 예방하기 위해서는 팀원 모두 참여해서 기술 이슈를 활발히 공유하고, 뭔가 불분명하다 싶으면 먼저 사실에 근거한 증거를 수집하고 프로토타입을 만들어 조사해야 한다.

## 4.4 성능 안티패턴 카탈로그

갖가지 성능 안티패턴을 유형별로 간략히 소개한다.

### 4.4.1 화려함에 사로잡히다.

* 문제상황\
    : 레거시 코드보다 신기술의 작동 원리를 연구하는 것이 더 재밌고, 코드도 관리하기 쉽다고 생각하여 최신의 멋진 기술을 튜닝타깃으로 정한다.
* 현실\
    : 신기술을 제대로 알지 못하는 상황에서 문서도 보지 않고 어설프게 지레짐작해서 다른 문제를 발생시킨다.
* 해결방안
    * 측정을 해보고 진짜 성능 병목점을 찾으세요.
    * 새 컴포넌트는 전후로 충분한 로그를 남기세요.
    * 베스트 프랙티스 및 단순화한 데모를 참조하세요.
    * 팀원들이 새 기술을 이해하도록 독려하고 팀 차원의 베스트 프렉티스 수준을 정하세요.

### 4.4.2 단순함에 사로잡히다.

* 문제상황\
    : 전체를 확인하지 않고 무작정 시스템에서 제일 간단한 부분만 파고든다.
* 현실\
    : 다양한 시스템 컴포넌트에 대해 지식 공유를 하지 않고 짝 프로그래밍을 안 한 결과, 독보적인 전문가만 양산되어 다른 사람은 문제를 해결하지 못한다.
* 해결방안
    * 본인이 익숙하지 않은 컴포넌트에 문제가 생기면 잘 아는 전문가에게 도움을 청하세요. 
    * 개발자가 전체 시스템 컴포넌트를 고루 이해하도록 독려하세요.

### 4.4.3 성능 튜닝 도사

* 문제상황\
    : 외부 성능 튜닝 전문가를 고용해 일을 맡긴다.
* 해결방안
    * 새로 채용된 팀내 전문가가 다른 팀원들과 지식을 공유하고 팀워크를 유지할 수 있게 리드하세요.

### 4.4.4 민간 튜닝

* 문제상황\
    : 검증되지 않은 방식으로 문제를 해결하려 한다.
* 현실\
    : 어떤 시스템에선 통했을지 모르지만 다른 시스템에 적용해도 효험이 있을지 모를 일이다.
* 진단\
    : 성능 팁은 유통 기한이 짧아 금세 낡은 유물이 되기 쉽다. 나중에 소프트웨어/플랫폼이 업데이트되고 새로운 해결책이 등장하면 무용지물이 되기 쉽다. 또한 자바 성능은 여러 가지 잡다한 요인이 영향을 미치는 맥락에서 발생하기 때문에 전후 맥락을 벗겨낸 나머지만 갖고는 거의 추론할 수가 없다.
* 해결방안
    * 충분히 검증된 것들만 적용하세요.
    * 매개 변수를 UAT 에서 시험해보세요. 어떤 변화라도 철저히 검증하고 효용을 프로파일링하는 일이 중요합니다.
    * 다른 개발자나 운영 요원, 데브옵스팀과 함께 설정 문제를 리뷰하고 검토합니다.

### 4.4.5 안되면 조상 탓

* 문제상황\
    : 정작 이슈와 아무 상관 없는 특정 컴포넌트를 문제 삼는다.
* 현실\
    : 충분히 분석도 안 해보고 성급한 결론을 내린다. 진짜 원인을 밝히려면 숲을 봐야 하는데 팀원들은 그럴 마음이 없다.
* 진단\
: 아무래도 뭔가 새로 조사하는 것보다는 보통 문제를 많이 일으키는 곳을 지목하는 게 편하기 때문에 이런 현상이 발생한다. 하이버네이트가 이러한 안티패턴의 좋은 예시인데, 과거 하이버네이트로 고생을 많이 한 경험이 있는 팀은 일단 문제가 발생했을 때 이 기술을 비난한다. 하지만 정작 문제는 하부 쿼리 문제, 부적절한 인덱스 사용 등 다른 곳에 있을 가능성이 크다. 따라서 정확한 원인을 밝히려면 프로파일링이 필수이다.
* 해결방안
    * 성급한 결론을 내리고픈 욕망에 굴하지 마세요.
    * 정상적으로 분석을 하세요.
    * 분석 결과를 모든 이해관계자와 의논하세요.

### 4.4.6 숲을 못 보고 나무만 보다.

* 문제상황\
    : 전체적인 변경 영향도를 완전히 파악하지 않은 채 일단 그냥 변경을 해보거나 애플리케이션의 국소적인 부분만 프로파일링한다.
* 현실\
    : 변경 영향도를 완전히 이해한 사람이 아무도 없다. 마이크로벤치마킹 때문에 빚어질 전체 시스템 영향도를 파악하지 않는다.
* 해결방안
    1. 운영계 성능 지표를 측정합니다.
    2. UAT에서 한번에 스위치 하나씩 변경합니다.
    3. 스트레스를 받는 지점이 UAT와 운영계가 동일한지 확인합니다.
    4. 운영계에서 일반적인 부하를 나타내는 테스트 데이터를 확보합니다.
    5. UAT에서 스위치를 변경하며 테스트합니다.
    6. UAT에서 다시 테스트합니다.
    7. 여러분이 추론한 내용을 다른 사람에게 재검토 요청합니다.
    8. 여러분이 내린 결론을 다른 사람과 공유합니다.

### 4.4.7 내 데스크톱이 UAT

* 문제상황\
    : UAT 환경이 운영계 환경과 전혀 다른 경우가 많다.
* 현실\
    : UAT 환경이 운영계와 달라서 서비스가 중단되는 사태가 벌어지면 장비 몇 대 추가하는 비용보다 훨씬 더 값비싼 대가를 치르게 된다.
* 해결방안
    * 서비스 중단 비용과 고객 이탈로 인한 기회비용을 잘 따져보세요.
    * 운영 환경과 동일한 UAT 환경을 구입하세요.
    
### 4.4.8 운영 데이터처럼 만들기는 어려워

* 문제상황\
    : 사람들이 운영계와 유사한 데이터를 나타내고자 할 때 빠지는 함정이다. 편의를 위해 테스트 과정을 단순화한다.
* 현실\
    : UAT 에서 정확한 결과를 얻으려면 운영계 데이터와 최대한 맞추어야 한다.
* 진단\
    : 운영 데이터와는 전혀 다른 모습이라도 이 정도면 되겠다, 싶은 데이터로 테스트할 때 진짜 결함이나 누락된 부분이 드러나는 경우도 있지만, 그릇된 판단을 내릴 소지가 다분한다.
* 해결방안
    * 데이터 도메인 전문가에게 컨설팅을 받고 운영 데이터를 UAT로 다시 이전하는 프로세스에 시간과 노력을 투자하세요.
    * 다수의 고객이 몰리고 엄청난 트랜잭션이 예상되는 서비스는 출시 전 철저히 준비하세요.


## 4.5 인지 편향과 성능 테스트

인지 편향은 인간의 두뇌가 부정확한 결론을 내리게 이끄는 심리 작용이다. 지금껏 살펴보았던 안티패턴 대부분, 전체/부분적으로는 하나 이상의 인지 편향으로 비롯된 것들이다. 편향을 보이는 사람이 대개 자신이 그런줄 모르고 스스로 아주 이성적이라고 믿는게 큰 문제이다.

### 4.5.1 환원주의

> 시스템을 아주 작은 조각으로 나누어 그 구성 파트를 이해하면 전체 시스템을 이해할 수 있다는 분석주의적 사고방식
* 복잡한 시스템은 단순히 구성 파트를 합친 것보다 시스템을 전체로 바라봐야 문제의 원인을 찾을 수 있다.

### 4.5.2 확증 편향

> '보고 싶은 것만 본다'

* 애플리케이션을 주관적으로 바라보게 한다.
* 일부러 그런 것은 아니지만 테스트 세트를 부실하게 선택하거나 테스트 결과를 통계적으로 건전하게 분석하지 않으면 확증 편향에 빠지기 쉽다.

### 4.5.3 전운의 그림자(행동 편향)

* 평소 로깅, 모니터링을 꾸준히 하면서 애플리케이션을 잘 가꾸어 오면 오류가 발생해도 명확한 에러 메시지가 생성되므로 금세 원인을 찾을 수 있다.
* 업무 담당자 모두 체계적으로 문제에 접근하는 태도를 길들이지 않으면 문제가 발생했을 때 획일적인 방향으로만 사고하게 되고 결국 더 큰 그림을 놓치게 된다.

### 4.5.4 위험 편향

> 위험을 피하고 변화를 거부한다.

* 단위 테스트 세트와 운영계 회귀 테스트 체계만 확실히 갖추고 나면 리스크를 상당히 줄일 수 있다.

### 4.5.5 엘스버그 역설

> 인간이 확률을 이해하는데 얼마나 서투른지 보여주는 사례이다.

## 4.6 마치며

* 성능 결과를 평가할 때는 데이터를 적절한 방법으로 처리하고 비과학적인, 주관적인 사고에 빠지지 않도록 조심해야 한다.
