<h1>하드웨어와 운영체제</h1>

<h3>메모리</h3>

 - 무어의 법칙에 따라 트랜지스터느 처음엔 클록 속도를 높이는데 쓰임.
 - 클록 속도가 증가했지만 칩이 빨라질수록 데이터도 더 빨리 움직여야 하는데, 시간이 갈수록 프로세서 코어의 데이터 수요를 메인 메모리가 맞추기 어려워짐.
 - 결국, 클록 속도가 올라가도 데이터가 도착할 때까지 cpu는 가다려야 하니 아무 소용이 없음.

<h5>메모리</h5>

 - cpu에 캐시를 추가함.(cpu 메모리 영역)
 - 자주 엑세스하는 메모리 위치는 cpu가 메인 메모리를 참조하지 않고 사본을 떠 cpu캐시에ㅔ 저장
 - cpu와 가까운 순서 L1,L2 식으로 단계를 거침.

   => 프로세서 처리율은 개선 => ※메모리에 있는 데이터를 어떻게 캐시로 가져오고 캐시한 데이터를 어떻게 메모리에 다시 써야할지 결정해야함 => 캐시 일관성 프로토콜 방법 사용

   프로세서의 가장 저수준에서 MESI라는 프로토콜

     - Modified(수정) : 데이터가 수정된 상태
     - Exclusive(배타) : 이 캐시에만 존재하고 메인 메모리 내용과 동일한 상태
     - Shared(공유) : 둘 이상의 캐시에 데이터가 들어 있고 메모리 내용과 동일한 상태
     - Invalid(무효) : 다른 프로세스가 데이터를 수정하여 무효한 상태

  동시 기록(라이트 - 스루) : 프로세스가 처음 나왔을 당시에 매번 캐시 연산 결과를 바로 메모리에 기록
  후 기록(라이트 - 백)    :  캐시 블록을 교체해도 프로세서가 변경된 캐시 블록만 메모리에 기록하므로 메인 메모리에 되돌아가는 트래픽이 떨어짐.


  최대 전송률을 결정하는 요소
      - 메모리 클록 주파수
      - 메모리 버스 폭
      - 인터페이스 개수

![KakaoTalk_20230714_162826666 - 복사본](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/b9b87f2f-e04d-4f9e-993c-da31c88f1a7d)
※일을 더 많이 한다고 소요시간이 확 줄지는 않는다.<br><br>         


<h5>변환 색인 버퍼(TLB)</h5>

=> 가장 메모리 주소를 물리 메모리 주소로 매핑하는 페이지 테이블의 캐시 역할을 수행 <br>

<h5>분기 예측과 추측 실행</h5>

 - 분기 예측은 프로세서가 조건 분기하는 기준값을 평가하느라 대기하는 현상을 방지함.
 - 다단계 명령 파이프라인에서는 조건물을 다 평가하기 전까지 분기 이후 다음 명령을 알 수 없는 게 문제임.
 - 휴리스틱 => 미리 추측한 결과를 바탕으로 파이프라인을 채움 => 추측이 맞아떨어지면 cpu는 다음 작업을 진행 or 틀리면 부분적으로 실행한 명령을 모두 폐기한 후 파이프라인을 비우는 대가를 치룸.

<h5>하드웨어 메모리 모델</h5>
"어떻게 하면 서로 다른 여러 cpu가 일관되게 동일한 메모리 주소를 액세스할 수 있을까?" <br>

코드 실행 순서를 바꿔도 현재 스레드가 바라보는ㄴ 결과는 아무런 영향이 없다는 전체로, <br>
JIT 컴파일러인 javac와 cpu는 일반적으로 코드 실행 순서를 바꿀 수 있다. <br> <br>

※멀티스레드 코드가 제대로 작동하게 하려면 락과 volatile을 정확히 알고 사용해야함.


<h3>운영체제</h3>

os의 주 임무는 여러 실행 프로세스가 공유하는 리소스 액세스를 관장하는 것. <br>

메모리 관리 유닛(MMU)는 가상 주소 방식과 페이지 테이블은 메모리 액세스 제어의 핵심으로서, 한 프로세스가 소유한 메모리 영역을 다른 프로세스가 함부로 훼손하지 못하게 함 <br>
=> 개발자가 세부적으로 공부 후 건들기엔 저수준..os엑세스 스케줄러를 살펴봅시다..<br>


<h5>스케줄러</h5>

- 프로세스 스케줄러는 cpu 액세스를 통제함.
- 기다리는 공간, 실행공간 모두 큐로 이뤄져있음.

![KakaoTalk_20230715_140658823_01](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/b547138c-c912-45e6-81fd-549783dbf020)

준비가 된 작업이 실행되며 스레드가 자신이 할당받은 시간을 자발적으로 포기하려면 sleep(), wait()메서드를 사용<br>
스레드는 I/O 또는 스프트웨ㅔ어 락에 걸려 블로킹 될 수 있다.<br>

※OS는 특성상 cpu에서 코드가 실행되지 않는 시간을 유발함.<br>
=> 자신의 할당 시간을 다 쓴 프로세스는 실행 큐 맨 앞으로 갈 때까지 cpu로 복귀하지 않는다. 이로 인해 cpu가 아껴 써야 할 리소스임을 감안하면 코드가 정작 실행되는 시간보다 기다리는 시간이 더 많다.(지터, 오버헤드)<br>

<h5>컨텍스트 교환</h5>

컨텍스트 교환은 OS 스케줄러가 현재 실행 중인 스레드,태스크를 없애고 대기 중인 다른 스레드/태스크로 대체하는 프로세스이다.<br>

유저모드 --> 커널모드 전환 시,<br>
유저 공간에 있는 코드가 액세스하는 메모리 영역은 커널 코드와 거의 공유할 부분이 없기 때문에 모드가 바뀌면 명령어와 다른 캐시를 어쩔 수 없이 강제로 비워야함.<br>
=> TLB를 비롯한 다른 캐시도 무효화가 됨.<br>
=> 이를 만회하기 위해 리눅스는 가상 동적 공유 객체(vDSO)라는 장치를 제공<br>
vDSO는 커널 프리빌리지가 필요 없는 시스템 콜의 속도를 높이려고 쓰는 유저 공간의 메모리 영역임.<br>

유닉스에서 쓰는 시스템 콜(gettimeofdy())를 사용하여 물팀에ㅔ서 커널 자료 구조를 읽어 시스템 클록 시간을 얻는다.=> 부수 효과를 일으키지 않아 프리비리지드 액세스는 필요없다.<br>
=> vDSO로 유저 프로세스의 주소 공간에 매핑시킬 수 있다면 커널 모드로 바꿀필요가 전혀 없다.<br>

<h3>기본 감지 전략</h3>

<h5>cpu 사용률</h5>

유저 스레드끼리든, 커널 공간 내부든 컨텍스트 교환은 cpu 리소스 낭비를 초래한다.<br>
측정 결과 왜 cpufmf 100%에 근접하지 않았다면 왜 그럴까? 따져봐야한다.<br>
대체 프로그램이 왜 cpu를 100% 사용하지 않았을까? 락 때문에 본의 아니게 발생한 컨텍스트 교환 때문인가? 아니면 I/O경합이 일어나 블로킹이 발생했나?<br><br>

유저 공간에서 cpu사용률이 100% 근처도 못 갔는데 어떤 프로세스에서 컨텍스트 교환 비율이 높게 나타나면 I/O에서 블로킹이 일어났거나, 스레드 락 경합상황이 벌어졌을 공산이 크다.<br>

<h5>가비지 수집</h5>

  - 어떤 시스템에서 cpu사용률이 아주 높게 나타난다면, GC는 대부분의 시간을 소비하는 줒범이 아니다.
  - GC 자체는 유저공간의 cpu 사이클을 소비하되 커널 공간의 사용률에는 영향을 미치지 않는 활동이다.
  - 반면, 어떤 jVM프로세스가 유저 공산에서 cpu를 100% 가깝게 사용하고 있다면 GC를 의심해야한다.

=> 유저 공간에서 이를 차지하는 비율이 JVm인지 유저코드인지 생각해봐야한다. jvm에서 유저 공간의 cpu사용률이 높은 건 거의 대부분 GC 서브시스템 탓이다.<br>
=> GC 로깅을 통해 성능 분석<br>

<h5>기계 공감</h5>

기계 공감 : 성능을 조금이라도 쥐어짜내야 하는 상황에서 하드웨어를 폭넓게 이해하고 공감할 수 있는 능력이 무엇보다 중요하다는 생각이다.<br>

ex)캐시 라인 동작
 => 멀티스레드 환경에서 두 스레드가 캐시 라인에 있는 변수를 읽거나 쓰려고 하면 문제가 된다.
 - 첫번째 스레드가 두 번째 스레드에 있는 캐시 라인을 무효화하면 메모리에서 다시 읽어 들어야한다.
 - 두 번째 스레드가 작업을 마치면 마찬가지로 첫 번재 스레드의 캐시 라인을 무효화한다.
 - 이렇게 주거니 받거니 잘못된 공유를 하고 결국 성능 급락으로 귀결됨.

<h3>가상화</h3>   

가상화는 이미 실행 중인 다른 OS위에서 OS 사본을 하나의 프로세스로 실행시키는 모양새가 보통이다.

가상화의 특징
  - 가상화 os에서 실행하는 프로그램은 베어메탈에서 실행할 때와 동일하게 작동해야 한다.
  - 하이퍼바이저는 모든 하드웨어 리소스 액세스를 조정해야 한다.
  - 가상화 오버헤드는 가급적 작아야 하며 실행시간의 상당 부분을 차지해선 안 된다.

   ⌦비가상화 시스템에서는 하드웨어를 직접 건드릴 수 있지만, 가상화 시스템에서는 게스트 os가 하드웨어에 직접 액세스할 수 없다.<br>

   하이퍼 바이저(Hypervisor)는 가상화 기술의 핵심 요소로서, 컴퓨터 시스템에서 가상 머신을 생성하고 관리하는 소프트웨어 또는 하드웨어입니다. <br>
   하이퍼 바이저는 가상 머신과 하드웨어 간의 인터페이스 역할을 수행하여 여러 개의 가상 머신이 단일 물리적 서버 또는 호스트에서 병렬로 실행될 수 있게 합니다.<br>

   











