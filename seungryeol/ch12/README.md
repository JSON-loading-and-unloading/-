<h1>동시 성능 기법</h1>

<h2>병렬성이란?</h2>

순차 실행 파트를 S, 총 태스크 소요 시간은 T라고 표기한다. 필요한 프로세서는 얼마든지 자유롭게 쓸 수 있다는 가정하에 프로세서 개수가 N이라고 하면,</br>
T는 프로세서 개수의 함수, 즉 T(N)으로 표기할 수 있다</br>
동시 작업은 T - S이고 N개 프로세스에 태스크를 고루 분배한다고 가정하면 전체 태스크 소요시간은 다음과 같다.</br>
```
T(N)  = S + (1/N) * (T - S)
```
프로세서를 무한히 증가시켜도 총 소요시간은 순차 작업 시간 이상 줄일 수가 없다.</br>
즉, 순차 오버헤드가 전체의 5%라고 하면 아무리 코어를 늘려도 20배 이상 속도를 높이는 건 불가능하다.</br>

이미지

더 빠른 코어를 장착하여 싱글 스레드 성능을 개선하면 S값을 줄일 수는 있겠지만, 아쉽게도 최신 하드웨어는 cpu클록 스피드를 높여도 그만한 속도 향상을 체감하기 어렵다.</br>


암달의 법칙에 따르면, 병렬 태스크나 다른 순차 태스크 간에 소통할 필요가 전혀 없을 경우 이론적으로 속도는 무한히 높일 수 있다.</br>
이런 부류의 워크로드를 낯간지러운 병렬이라고한다.</br>

보통 데이터 공유없이 워크로드를 나누어 여러 워커 스레드에 분산시킨다.</br>
스레드끼리 상태나 데이터를 공유하기 시작하면 워크로드는 점차 복잡해지면서 결국 어쩔 수 없이 일부 태스크를 순차 처리하게 되고 통신 오버헤드가 발생한다.</br>
=> 상태를 공유하는 워크로드는 무조건 정교한 보호/제어 장치가 필요하다. 자바 플랫폼은 jvm에서 실행되는 워크로드에 jmm이라는 메모리 보증 세트를 제공한다.</br>

![KakaoTalk_20230925_200936730_01](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/8d4ac962-c98c-43d6-9d00-a7996a212e73)

두 스레드가 A, B가 있고 둘 다 같은 객체의 increment()메서드를 호출한다.</br>

각 스레드는 메서드 개별 진입 시 각자 전용 평가 스택을 소유하므로 필드에 대한 작업은 서로 간섭이 일어날 수 있다.</br>
=> A나 B가 실행되기 전 i의 초기 상태가 7이고 정확히 위 순서대로 실행된다고 하면, 두 차례 호출 결과 모두 8이 반환되고 필드는 i는 8이 될 것이다.</br>
※volatile을 추가하면 안전하게 증분 연산을 할 수 있을 것처럼 보이지만 그건 오산이다.(무조건 값을 캐시에서 다시 읽어들여 다른 스레드가 수정된 값을 바라보게 할 수는 있지만,증분 연산자의 복합적인 특성 탓에 방금 전 업데이트 소실 문제를 막을 수는 없다.)
</br></br>

다음은 두 스레드가 동일한 카운터의 레퍼런스를 공유하는 코드이다.</br>

![KakaoTalk_20230925_200936730_02](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/82181b5c-987c-4ea8-a454-e3ee7e3cec81)

synchronized나 락으로 감싸지 않은 채 카운터로 무방이가 노출돼 있어서 프로그램을 돌릴 때마다 두 스레드는 갖가지 형태로 셔로 엮일 공간이 크다.</br>

동기화를 사용할 때는 아주 신중하게 설계하고 미리 잘 따져봐야 한다는 부담이 따른다.</br>
아무 생각 없이 synchronized만 달랑 추가했다간 프로그램이 빨라지기는커녕 더 느려질 수도 있다.</br>
이처럼 처리율 향상은 동시성을 부여하는 전체 목표와 상충된다. 따라서 코드 베이스를 병렬화하는 작업을 진행할 때에는 복잡도가 늘어난 대가로 얻은 혜택을 충분히 입증할 수 있도록
성능 테스트가 수반되어야한다.</br></br>

<h2>JMM의 이해</h2>

jmm은 다음 질문에 답을 찾는 모델이다.</br>
- 두 코어가 같은 데이터를 액세스하면 어떻게 되는가?
- 언제 두 코어가 같은 데이터를 바라본다고 장담할 수 있는가?
- 메모리 캐시는 위 두 질문의 답에 어떤 영향을 미치는가?


자바 플랫폼은 공유 상태를 어디서 액세스하든지 jmm이 약속한 내용을 반드시 이행한다.</br>
그 약속이란, 순서에 관한 보장과 여러 스레드에 대한 업데이터 가시성 보장, 두 가지로 분류된다.</br>


고수준에서 jmm같은 메모리 모델은 두 가지 방식으로 접근한다.</br></br>

<h4>강한 메모리 모델</h4>
 전체 코어가 항상 같은 값을 바라본다.

<h4>약한 메모리 모델</h4> 
코어마다 다른 값을 바라볼 수 있고 그 시점을 제어하는 특별한 캐시 규칙이 있다.


![KakaoTalk_20230925_200936730](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/9438ed0b-ae61-453e-8b2b-98282194f6f3)

하드웨어에 강한 메모리 모델을 구현하면 사실상 메모리를 후기록하는 것과 같다.</br>
캐시 무효화 알림이 메모리 버스를 잠식하고 실제 메인 메모리 전송률은 급락한다.</br>
코어 수를 늘리는 건 상황을 더욱 악화시킬 뿐이라서 이런 방법은 근본적으로 멀티코어 체제에는 안맞다.</br>

자바는 아키텍처에 독립적인 환경으로 설계된 플랫폼이다. 만약 jvm이 강한 메모리 모델 기반으로 설계됐다면,</br>
네이티브 수준에서 강한 메모리 모델을 지원하지 않는 하드웨어에서 소프트웨어를 실행하기 위해서는 jvm에 별도 구현 작업이 필요하다.</br>
다시 말해, 약한 하드웨어상에서 jvm을 구현하려면 엄청난 이식 작업이 수반되어야 한다.</br></br>


jmm보다 더 강한 메모리 모델 기반의 하드웨어 플랫폼에서 개발된 애플리케이션은 동시성 버그를 갖고 있을 가능성이 있다.</br>
=> 하드웨어가 보장해주는 탓에 실제로 이런 버그가 잘 드러나지 않기 때문이다.</br>
   똑같은 애플리케이션을 약한 하드웨어에 배포하면 하드웨어가 더 이상 보호해주지 못하는 까닭에 내재되어 있던 동시성 버그가 문제가 된다.</br>
   - Happens - Before( 한 이벤트는 무조건 다른 이벤트보다 먼저 발생한다.)
   - Synchronizes-With(이벤트가 객체 뷰를 메인 메모리와 동기화시킨다.)
   - As-If-Serial(실행 스레드 밖에서는 명령어가 순차 실행되는 것처럼 보인다.)
   - Release-Before-Acquire( 한 스레드에 걸린 락을 다른 스레드가 그 락을 확득하기 전에 해제한다.)

자바에서 스레드는 객체 상태 정보를 스스로 들고 다니며, 스레드가 변경한 내용은 메인 메모리로 곧장 반영되고 같은 데이터를 액세스하는 다른 스레드가 다시 읽은 구조이다.</br>
jvm에는 저수준 메모리 액세스를 감싸놓은 구현 코드가 상당히 많다.</br></br>


동기화 메서드, 동기화 블록은 스레드가 반드시 동기를 맞춰야 할 접점에 해당하며 다른 동기화 메서드/블록이 시작되기 전에 반드시 완료되어야 할 코드 블록을 정의해 놓은 것이다.</br>

jmm으느 동기화되지 않은 액세스에 대해서는 아무 할 말이 없다.</br>
한 스레드가 변경한 부분을 다른 스레드가 언제 바라볼 수 있는지 전혀 보장하지 않는다.</br>
그런 보장이 필요하면 반드시 쓰기 액세스를 동기화 블록으로 감싸 캐시된 값을 메모리에 후기록해야한다.</br>
마찬가지로 읽기 엑세스도 동기화 코드 섹션 내부에 넣어서 강제로 메모리를 다시 읽도록 해야한다.</br></br>

최근 자바 동시성 기술이 선보이지 전에는 synchronized 키워드가 멀티스레드 순서와 가시성을 보장하는 유일한 장치였다.</br></br>

기본 자바 synchronized 락은 여러 한계점이 노출됐는데, 시간이 갈수록 그 증상이 심각해졌다.</br>
- 락이 걸린 객체에서 일어나는 동기화 작업은 모두 균등하게 취급한다.
- 락 획득/해제는 반드시 메서드 수준이나 메서드 내부 동기화 블록 안에서 이루어져야 한다.
- 락을 얻지 못한 스레드는 블로킹된다. 락을 얻지 못할 경우, 락을 얻어 처리를 계속하려고 시도하는 것조차 불가능하다.

  락이 걸리 데이터에 관한 모든 연산이 동등하게 취급된다는 사실을 놓치는 경우가 참 많다.</br>
  따라서 쓰기 작업에만 synchronized를 적용하면 소실된 업데이트 현상이 나타나게 된다.</br>
  읽기 작업에는 락을 걸 필요가 없을 것 같지만, 다른 스레드가 업데이터한 내용을 바라보게 하려면 반드시 synchronized를 사용해야한다. </br></br>


<h2>동시성 라이브러리 구축</h2>

java.util.concurrent 패키지는 멀티스레드 애플리케이션을 자바로 더 쉽게 개발할 수 있게 세심하게 설계된 라이브러리이다.</br>
추상화가 잘 된 java.util.concurrent 라이브버리를 골라 쓰면 '스레드 핫'성능도 함께 좋아진다.</br>

라이브러리를 구성하는 핵심 요소</br>
- 락, 세마포어
- 아토믹스
- 블로킹 큐
- 래치
- 실행자

 
![KakaoTalk_20230926_103316140](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/01b6cc25-248b-4c86-a4ac-f28903ed0923)

  일반적으로 라이브러리는 os 품에서 벗어나 가급적 유저 공간에서 더 많은 일을 하려고 한다.</br>
  이렇게 하면 여러 가지로 장점이 있지만, 특히 라이브러리 로직이 유닉스 계열 os마다 존재하는 차이점 때문에 오락가락하지 않고 가급적 더 전역 범위에서</br>
  일관성을 보장한다는 측면에서 증요하다.</br>

  일부 라이브러리는 비교해서 바꾸기(cas)라는 기법을 구현하기 위해 저수준 프로세서 명령어 및 os별 특성을 활용한다.</br>

  CAS는 '예상되는 현재 값과 원하는 새 값, 그리고 메모리 위치를 전달받아 다음 두 가지 일을 하는 아토믹 유닛이다.</br>
  1. 예상되는 현재 값을 메모리 위치에 있는 콘텐츠와 비교한다.
  2. 두 값이 일치하면 현재 값을 원하는 새 값으로 교체한다.

  CAS는 구현체별 확장 기능이라고 볼 수 있으므로 CAS 하드웨어는 sun.misc.Unsafe클래스를 통해 액세스한다..</br>

  <h3>Unsafe</h3>

  unsafe 이 클래스는 사용하는 코드는 엄밀히 말해 핫스팟 vm에 직접 연결되고 깨질 우려가 높다.</br>

  Unsafe로 할 수 있는 일</br>
  - 객체를 할당하지만 생성자는 실행하지 않는다.
  - 원메모리에 액세스하고 포인터 수준의 연산을 수행한다.
  - 프로세서별 하드웨어 특정을 이용한다.

    고수준의 프레임워크 기능 구현 목록</br>
    - 신속한 직렬화
    - 스레드-안전한 네이티브 메모리 액세스
    - 아토믹 메모리 연산
    - 효율적인 객체/메모리 레이아웃
    - 커스텀 메모리 펜스
    - 네이티브 코드와의 신속한 상호작용
    - JNI에 관한 다중 운영체제 대체물
    - 배열 원소에 volatile하게 액세스

  <h3>아토믹스와 CAS</h3> 
  아토믹스는 값을 더하고 증간하는 복합 연산을 하며 get()으로 계산한 결괏값을 돌려받는다.</br>
  아토믹 변수는 volatile확장판이라고 할 수 있지만, volatile보다 더 유연해서 상태 의존적업데이트를 안전하게 수행할 수 있다.</br></br>

  아토믹스는 자신이 감싸고 있는 베이스 타입을 상속하지 않고 직접 대체하는 것도 허용되지 않습니다.</br>
  (예를 들어 AtomicInteger는 Integer를 상속한 클래스가 아니다. 사실 java.lang.Integer가 final클래스라서 불가능하다.)</br>

  ![KakaoTalk_20230926_103316140_01](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/f63f3cba-f102-440e-8d5b-beca7cc0e5b8)

Unsafe에 있는 메서드를 사용했고 JVM을 호출하는 네이티브 코드가 핵심</br>

![KakaoTalk_20230926_103316140_02](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/046f434f-4990-4064-b67e-afa7d87d5533)


  Unsafe 내부에서 루프를 이용해 CAS 작업을 반복적으로 재시도한다.</br>
  아토믹스 효과적으로 활용하려면 주어진 기능 외에 임의로 코드를 구현해서 섞어 쓰지 말아야 한다.</br>
  가령, 루프를 이용해 아토믹 증분 연산을 하는 코드는 이미 Unsafe에 그렇게 구현되어 있으니 필요가 없다.</br>
  아토믹 락-프리하므로 데드락이 있을 수 없다. 비교 후 업데이트하는 작업이 실패할 경우를 대비해 내부적으로 재시도 루프가 동반된다.</br></br>

  변수를 업데이트하기 위해 여러 차례 재시도를 해야 할 경우, 횟수만큼 성능이 나빠진다.</br>
  성능을 고려할 때에는 처리율을 높은 수준으로 유지하기 위해 경합 수준을 잘 모니터링해야 한다.</br>

  <h3>락과 스핀락</h3>

인트린직 락은 유저 코드에서 OS를 호출하므로써 작동한다.</br>
OS를 이용해 스레드가 따로 신호를 줄 때까지 무한정 기다리게 만드는 것이다. 경합 중인 리로스가 극히 짧은 시간동암난 사용할 경우 이런 방식은 막대한 오버헤드를 유발할 수 있다.</br>
스핀락 : 블로킹된 스레드를 cpu에 활성 상태로 놔두고 아무 일도 시키기 않은 채 락을 손에 넣을 때까지 cpu를 태워가며 계속 재시도학게 만드는 편이 더 효율적이다.</br>

스핀락은 cpu마다 조금씩 다르지만, 핵심 개념은 동일</br>
- 테스트하고 세팅하는 작업은 반드시 아토믹해야한다.
- 스핀락에 경합이 발생하면 대기 중인 프로세서는 빽빽한 루프를 실행하게 된다.

  cas는 예상한 값이 정확할 경우 한 명령어로 값을 안전하게 업데이트하며, 락의 구성 요소를 형성한는데 한몫을 한다.</br>

<h2>동시성 라이브러리 정리</h2>

<h3>java.util.concurrent</h3>

  일반화한 락 인터페이스가 java.util.concurrent.locks.Lock에 추가됐습니다.</br>
  (이 인터페이스를 이용하면 인트린직 락보다 더 많은 일을 할 수 있다.)</br>

 <h4>lock()</h4>
  기존 방식대로 락을 획득하고 락을 사용할 수 있을 때까지 블로킹한다.

 <h4>newCondition()</h4>
 락 주위에 조건을 설정해 좀 더 유연하게 락을 활용합니다. 락 내부에서 관심사를 분리할 수 있다.

 <h4>tryLock()</h4>
 락을 획득하려고 시도한다. 덕분에 스레드가 락을 사용할 수  없는 경우에도 계속 처리를 진행할 수 있다.
 
 <h4>unlock()</h4>
 락을 해제한다. lock()에 대응되는 후속 호출이다.
</br>
 여러 종료의 락을 생성할 수 있고 여러 메서드에 걸쳐 락을 걸어놓은 것도 가능한다.</br>
 심지어 한 메서드에서는 락을 걸고 동시에 다른 메서드는 락을 해제할 수도 있다. 논 블로킹 방식으로 락을 획득하려는 스레드는 trtLock()메서드로</br>
 일단 시도해보고 락을 사용할 수 없을 경우 다시 물러나면된다.

 ReentrantLock은 Lockd의 주요 구현체, 내부적으로는 int 값으로 compareAndSwap()을 한다.</br>
 즉, 경합이 없는 경우에는 락을 획들가흔 과정이 락-프리하다.</br>
 => 락 경합이 별로 생기지 않는 시스템은 성능이 매우 좋아지고 다양한 락킹 정책을 적용 가능한 유연성도 얻게 된다.</br></br>

 compareAndSwap()을 호출하고 Unsafe를 시용한 코드는 AbstractQueuedSynchronizer를 확장한 정적 서브클래스 Sync에 있다.</br>
 또 AbstractQueuedSynchronizer는 스레드를 파킹 및 재개하는 메서드가 구현된 LockSupport 클래스를 활용한다.</br></br>

 LockSupport클래스는 스레드에게 퍼밋을 발급한다. 발급할 퍼밋이 없으면 스레드는 기다려야한다.</br>
 퍼밋을 발급하는 개념 자체는 세마포어와 비슷하지만, LockSupport클래스는 오직  한 가지 퍼밋만 발급한다.</br>
 스레드는 퍼밋을 받지 못한 경우 잠시 파킹되었다가, 유효한 퍼밋을 받을 수 있을 때 다시 언파킹된다.</br></br>

 park()메서드 세 가지</br>
<h4>park(Object blocker)</h4>
  다른 스레드가 unpark()을 호출하거나, 스레드가 인터럽트되거나, 또는 스퓨리어스 웨이크업이 발생할 때까지 블로킹된다.

<h4>parkNanos(Object blocker, long nanos)</h4>
  park()와 같고 나노초 단위로 지정한 시간이 지나면 그냥 반환

<h4>parkUntil(Object blocker, long deadline)</h4>
  park()와 같고 ms 단위로 지정한 시간이 지나면 그냥 반환

<h3>읽기/쓰기 락</h3> 
 애플리케이션에 있는 컴포넌트는 대부분 읽기와 쓰기 작업 횟수가 많이 차이난다.</br>
 읽기는 상태를 바꾸지 않지만 쓰기는 상태를 바꾼다. 기존 synchronized나 ReentrantLock을 이용하면 한 가지 락 정책을 따를 수밖에 없다.</br>
 여러 읽기 스레드가 하나의 쓰기 스레드에 달려두는 상황에서는 어느 한 읽기 스레드 때문에 나머지 읽기 스레드를 블로킹하느라 불필요한 시간을 허비할 가능성이 있다.</br>

 => ReentrantReadWriteLock 클래스의 ReadLock과 WriteLock을 활용하면 여러 스레드가 읽기 작업을 하는 도중에도 다른 읽기 스레드를 블로킹하지 않게 할 수 있다.</br>

![KakaoTalk_20230926_122030212](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/ee7e3474-72d5-48db-9c9b-de684224537f)
![KakaoTalk_20230926_122030212_01](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/ffa9495e-9d54-41a2-8887-220a61ca2cd3)

 단일 락을 사용했을 때보다 현저히 향상</br>

 
 <h3>세마포어</h3>

 세마포어는 풀 스레드나 DB 접속 객체 등 여러 리소스의 액세스를 허용하는 독특한 기술을 제공한다.</br>

 ```
private Semaphore poolPermits = new Semaphore(2, true)
```
Semaphore 클래스의 acquire()메서드는 사용 가능한 퍼밋 수를 하나씩 줄이는데, 더 이상 쓸 수 있는 퍼밋이 없을 경우 블로킹한다.</br>
release()메서드는 퍼밋을 반납하고 대기 중인 스레드 중에서 하나에게 해제한 퍼밋을 전달한다.</br>
세마포어를 사용하면 리소스가 블로킹되거나 리소스를 기다리는 큐가 형성될 가능성이 커서 스레드 고갈을 막기 위해 처음부터 공정모드로 초기화하는 경우가 많다.
</br>
퍼밋이 하나뿐인 세마포어는 뮤텍스와 동등하다. 그러나 뮤텍스는 뮤텍스가 걸린 스레드만 해제할 수 있는 반면, 세마포어는 비소유스레드도 해제할 수 있다는 점이 다르다.</br>
데드락을 강제로 해결해야 할 경우 필요한 방법이다. 세마포어의 강점은 여러 퍼밋을 획득/해제할 수 있는 능력이다. 퍼밋을 여러 개 쓸 경우, 불공정 모드에선 스레드가 고갈될 가능성이 크기 때문에 공정 모드는 필수이다.</br>

 
 <h3>동시 컬렉션</h3>

 자바 동시 컬렉션은 시간이 지나면서 스레드 핫 성능을 최고로 뽑아낼 수 있는 방향으로 조금씩 수정/보안돼 왔다.</br>

ex) </br>
 Map 구현체는 버킷 또는 세그먼트로 분할된 구조를 최대한 활용하여 실질적인 선능 개선 효과를 얻는다. 각 세그먼트는 자체 락킹 정책, 즉 자기만의 락 세트를 가질 수 있다.</br>
 따라서 읽기/쓰기 락을 둘 다 소유한 상태에서 여러 읽기 스레드가 ConcurrentHashMap 곳곳을 읽는 동안, 쓰기가 필요할 경우 어느 한 세그먼트만 락을 거는 행위도 가능하다.</br></br>

 이터레이터는 일종의 스냅샷으로 획득하기 때문에 ConcurrentModiFicationException이 발생할 일은 없단느 사실이 중요하다.</br>
 충돌이 많은 경우 테이블이 동적으로 팽창하는데, 이런 작업은 꽤 비용이 많이 들기 마련이라 코드를 작성할 때 대략 예상되는 크기를 미리 지정하는 편이 좋다.</br></br>

 자바5부터 CopyOnWriteArrayList, CopyOnWriteArraySet이 새로 도입돼서 이떤 사용패턴에서는 멀티스레드 성능이 향상될 수 있다. 이 두 클래스에서 자료 구조를 변경하면 배킹 </br>배열 사본이 하나 더 생성된다. 덕분에 기존 이터레이터는 예전 배열을 계속 탐색할 수 있고, 레퍼런스가 하나도 없게 되면 이 예전 배열 사본은 가비지 수집 대상이 된다.</br>
 이렇게 스냅샷 스타일로 이터레이션하므로 ConcurrentModiFicationException이 일어날 가능성이 없다.</br></br>

 이 방식은 카피-온-라이트 자료구조를 변경하는 횟수보다 읽는 횟수가 월등히 많은 시스템에서 잘 작동한다.</br>
 
  
 <h3>래치와 배리어</h3>

 워커 스레드로 작업 진행 상황</br>
 1. API로 데이터를 조회 후 파싱한다.
 2. 그 결과를 DB에 쓴다.
 3. 끝으로, SQL쿼리로 결괏값을 계산한다.

모든 스레드가 task1 => task2 => task3 순서로 진행되는 것이 이상적이라면 래치를 쓰기에 딱 좋은 경우이다.</br>
실행 스레드 5개 배정한다고 가정 코드</br>

![KakaoTalk_20230926_122030212_02](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/1a914833-8386-4627-a3a8-5f69948fb319)
![KakaoTalk_20230926_122030212_03](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/fc78654c-1bf5-4dcf-adf2-3eb58829c4ee)

래치 카운트는 처음에 5로 세팅하고 각 스레드가 countdown()을 호출할 때마다 카운트 값은 1만큼 감소한다.</br>
카운트가 결국 0에 이르면 래치가 열리고 await()함수 때문에 매여 있던 스레드가 모두 해제되어 처리를 재개한다.</br>
(래치는 단 한번밖에 사용할 수 없다)</br>

위 예제에서 래치를 두 가지 써서, API 결과가 완료되는 시점에, 또 다른 하나의 DB결과가 완료되는 시점에 적용하는 방법도 있다.</br>

리셋이 가능한 CyclicBarrier를 사용하는 방법도 있지만, 어느 스레드가 리셋을 제어할지 판단하기가 제법 까다롭고 또 다른 종류의 동기화가 개입되어 복잡해진다.</br>
파이프라인 각 단체마다 하나의 배리어/래치를 적용하는 것이 일반적인 베스트 프랙티스이다.</br>

