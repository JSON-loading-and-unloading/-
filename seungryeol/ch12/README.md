<h1>동시 성능 기법</h1>

<h2>병렬성이란?</h2>

순차 실행 파트를 S, 총 태스크 소요 시간은 T라고 표기한다. 필요한 프로세서는 얼마든지 자유롭게 쓸 수 있다는 가정하에 프로세서 개수가 N이라고 하면,</br>
T는 프로세서 개수의 함수, 즉 T(N)으로 표기할 수 있다</br>
동시 작업은 T - S이고 N개 프로세스에 태스크를 고루 분배한다고 가정하면 전체 태스크 소요시간은 다음과 같다.</br>
```
T(N)  = S + (1/N) * (T - S)
```
프로세서를 무한히 증가시켜도 총 소요시간은 순차 작업 시간 이상 줄일 수가 없다.</br>
즉, 순차 오버헤드가 전체의 5%라고 하면 아무리 코어를 늘려도 20배 이상 속도를 높이는 건 불가능하다.</br>

이미지

더 빠른 코어를 장착하여 싱글 스레드 성능을 개선하면 S값을 줄일 수는 있겠지만, 아쉽게도 최신 하드웨어는 cpu클록 스피드를 높여도 그만한 속도 향상을 체감하기 어렵다.</br>


암달의 법칙에 따르면, 병렬 태스크나 다른 순차 태스크 간에 소통할 필요가 전혀 없을 경우 이론적으로 속도는 무한히 높일 수 있다.</br>
이런 부류의 워크로드를 낯간지러운 병렬이라고한다.</br>

보통 데이터 공유없이 워크로드를 나누어 여러 워커 스레드에 분산시킨다.</br>
스레드끼리 상태나 데이터를 공유하기 시작하면 워크로드는 점차 복잡해지면서 결국 어쩔 수 없이 일부 태스크를 순차 처리하게 되고 통신 오버헤드가 발생한다.</br>
=> 상태를 공유하는 워크로드는 무조건 정교한 보호/제어 장치가 필요하다. 자바 플랫폼은 jvm에서 실행되는 워크로드에 jmm이라는 메모리 보증 세트를 제공한다.</br>

![KakaoTalk_20230925_200936730_01](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/8d4ac962-c98c-43d6-9d00-a7996a212e73)

두 스레드가 A, B가 있고 둘 다 같은 객체의 increment()메서드를 호출한다.</br>

각 스레드는 메서드 개별 진입 시 각자 전용 평가 스택을 소유하므로 필드에 대한 작업은 서로 간섭이 일어날 수 있다.</br>
=> A나 B가 실행되기 전 i의 초기 상태가 7이고 정확히 위 순서대로 실행된다고 하면, 두 차례 호출 결과 모두 8이 반환되고 필드는 i는 8이 될 것이다.</br>
※volatile을 추가하면 안전하게 증분 연산을 할 수 있을 것처럼 보이지만 그건 오산이다.(무조건 값을 캐시에서 다시 읽어들여 다른 스레드가 수정된 값을 바라보게 할 수는 있지만,증분 연산자의 복합적인 특성 탓에 방금 전 업데이트 소실 문제를 막을 수는 없다.)
</br></br>

다음은 두 스레드가 동일한 카운터의 레퍼런스를 공유하는 코드이다.</br>

![KakaoTalk_20230925_200936730_02](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/82181b5c-987c-4ea8-a454-e3ee7e3cec81)

synchronized나 락으로 감싸지 않은 채 카운터로 무방이가 노출돼 있어서 프로그램을 돌릴 때마다 두 스레드는 갖가지 형태로 셔로 엮일 공간이 크다.</br>

동기화를 사용할 때는 아주 신중하게 설계하고 미리 잘 따져봐야 한다는 부담이 따른다.</br>
아무 생각 없이 synchronized만 달랑 추가했다간 프로그램이 빨라지기는커녕 더 느려질 수도 있다.</br>
이처럼 처리율 향상은 동시성을 부여하는 전체 목표와 상충된다. 따라서 코드 베이스를 병렬화하는 작업을 진행할 때에는 복잡도가 늘어난 대가로 얻은 혜택을 충분히 입증할 수 있도록
성능 테스트가 수반되어야한다.</br></br>

<h2>JMM의 이해</h2>

jmm은 다음 질문에 답을 찾는 모델이다.</br>
- 두 코어가 같은 데이터를 액세스하면 어떻게 되는가?
- 언제 두 코어가 같은 데이터를 바라본다고 장담할 수 있는가?
- 메모리 캐시는 위 두 질문의 답에 어떤 영향을 미치는가?


자바 플랫폼은 공유 상태를 어디서 액세스하든지 jmm이 약속한 내용을 반드시 이행한다.</br>
그 약속이란, 순서에 관한 보장과 여러 스레드에 대한 업데이터 가시성 보장, 두 가지로 분류된다.</br>


고수준에서 jmm같은 메모리 모델은 두 가지 방식으로 접근한다.</br></br>

<h4>강한 메모리 모델</h4>
 전체 코어가 항상 같은 값을 바라본다.

<h4>약한 메모리 모델</h4> 
코어마다 다른 값을 바라볼 수 있고 그 시점을 제어하는 특별한 캐시 규칙이 있다.


![KakaoTalk_20230925_200936730](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/106163272/9438ed0b-ae61-453e-8b2b-98282194f6f3)

하드웨어에 강한 메모리 모델을 구현하면 사실상 메모리를 후기록하는 것과 같다.</br>
캐시 무효화 알림이 메모리 버스를 잠식하고 실제 메인 메모리 전송률은 급락한다.</br>
코어 수를 늘리는 건 상황을 더욱 악화시킬 뿐이라서 이런 방법은 근본적으로 멀티코어 체제에는 안맞다.</br>

자바는 아키텍처에 독립적인 환경으로 설계된 플랫폼이다. 만약 jvm이 강한 메모리 모델 기반으로 설계됐다면,</br>
네이티브 수준에서 강한 메모리 모델을 지원하지 않는 하드웨어에서 소프트웨어를 실행하기 위해서는 jvm에 별도 구현 작업이 필요하다.</br>
다시 말해, 약한 하드웨어상에서 jvm을 구현하려면 엄청난 이식 작업이 수반되어야 한다.</br></br>


jmm보다 더 강한 메모리 모델 기반의 하드웨어 플랫폼에서 개발된 애플리케이션은 동시성 버그를 갖고 있을 가능성이 있다.</br>
=> 하드웨어가 보장해주는 탓에 실제로 이런 버그가 잘 드러나지 않기 때문이다.</br>
   똑같은 애플리케이션을 약한 하드웨어에 배포하면 하드웨어가 더 이상 보호해주지 못하는 까닭에 내재되어 있던 동시성 버그가 문제가 된다.</br>
   - Happens - Before( 한 이벤트는 무조건 다른 이벤트보다 먼저 발생한다.)
   - Synchronizes-With(이벤트가 객체 뷰를 메인 메모리와 동기화시킨다.)
   - As-If-Serial(실행 스레드 밖에서는 명령어가 순차 실행되는 것처럼 보인다.)
   - Release-Before-Acquire( 한 스레드에 걸린 락을 다른 스레드가 그 락을 확득하기 전에 해제한다.)

자바에서 스레드는 객체 상태 정보를 스스로 들고 다니며, 스레드가 변경한 내용은 메인 메모리로 곧장 반영되고 같은 데이터를 액세스하는 다른 스레드가 다시 읽은 구조이다.</br>
jvm에는 저수준 메모리 액세스를 감싸놓은 구현 코드가 상당히 많다.</br></br>


동기화 메서드, 동기화 블록은 스레드가 반드시 동기를 맞춰야 할 접점에 해당하며 다른 동기화 메서드/블록이 시작되기 전에 반드시 완료되어야 할 코드 블록을 정의해 놓은 것이다.</br>

jmm으느 동기화되지 않은 액세스에 대해서는 아무 할 말이 없다.</br>
한 스레드가 변경한 부분을 다른 스레드가 언제 바라볼 수 있는지 전혀 보장하지 않는다.</br>
그런 보장이 필요하면 반드시 쓰기 액세스를 동기화 블록으로 감싸 캐시된 값을 메모리에 후기록해야한다.</br>
마찬가지로 읽기 엑세스도 동기화 코드 섹션 내부에 넣어서 강제로 메모리를 다시 읽도록 해야한다.</br></br>

최근 자바 동시성 기술이 선보이지 전에는 synchronized 키워드가 멀티스레드 순서와 가시성을 보장하는 유일한 장치였다.</br></br>

기본 자바 synchronized 락은 여러 한계점이 노출됐는데, 시간이 갈수록 그 증상이 심각해졌다.</br>
- 락이 걸린 객체에서 일어나는 동기화 작업은 모두 균등하게 취급한다.
- 락 획득/해제는 반드시 메서드 수준이나 메서드 내부 동기화 블록 안에서 이루어져야 한다.
- 락을 얻지 못한 스레드는 블로킹된다. 락을 얻지 못할 경우, 락을 얻어 처리를 계속하려고 시도하는 것조차 불가능하다.

  락이 걸리 데이터에 관한 모든 연산이 동등하게 취급된다는 사실을 놓치는 경우가 참 많다.</br>
  따라서 쓰기 작업에만 synchronized를 적용하면 소실된 업데이트 현상이 나타나게 된다.</br>
  읽기 작업에는 락을 걸 필요가 없을 것 같지만, 다른 스레드가 업데이터한 내용을 바라보게 하려면 반드시 synchronized를 사용해야한다. </br></br>



