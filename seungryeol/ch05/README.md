<h1>마이크로벤치마킹과 통계</h1>


<h2>자바 성능 측정 기초</h2>

벤치마크 : 컴퓨터 시스템, 프로그램, 알고리즘 등의 성능을 측정하고 비교하는 데 사용되는 기술 또는 절차<br>

- 가급적 시스템의 어느 한 곳만 변경하고 다른 외부 요인은 벤치마크 안에 두고 통제하면 좋다.
- 시스템에서 가변적인 부분은 테스트 간에 불변성을 유지해야 하면 좋다.

  자바 플랫폼을 벤치마크할 때에는 자바 런타임의 정교함이 문제이다. => 선택지가 제한적이다.<br>
  => 최적화가 미치는 영향을 구체적으로 완전히 이해하고 설명하기 불가능하다.<br>
  
  ※ 큰 단위 벤치마킹으로 처리하여 상쇄시킬 수 있지만 마이크로벤치마크를 할 때는 코드를 떼어놓기가 어렵다.<br>

  벤치마크 할 때의 실수<br>

  1. JVM웜엄을 전혀 고려하지 않은 채 그냥 코드를 테스트한다.<br>

  Jit 컴파일러는 코드를 조금이라도 효율적으로 작동시키려고 호출 계층을 최적화하므로 벤치마크 성능은 캡처 타이밍에 따라 달라짐.<br>

   - 타이밍을 캡처하기 전에 JVM이 가동 준비를 마칠 수 있게 웜업 기간을 두는게좋다.( 충분히 jit컴파일러가 작동하여 캐시 역할 수행)
   - 타이밍 캡처 도중에 GC가 안 일어나게 설정한 다음 가동시키면 좋다.
 

2. 테스트하려는 코드에서 생성된 결과를 실제로 사용하지 않는다.<br>

  -  jit컴파일러가 죽은 코드로 식별하고 벤치마크하려던 것을 최적화해버릴 가능성이 있다.<br>
  -  
3. 한번 측정한 결과로는 평균을 내도 벤치마크가 어떻게 수행됐는지 전체 사정을 알 수 없다.<br>

   - 허용 오차를 구해 수집한 값의 신뢰도를 파악하면 좋다.<br>
     => 허용 오차가 큰 것은 통제불능 변수가 있거나, 개발된 코드 자체가 성능 기준에 미치지 못한다.<br>


엉뚱한 벤치마크 결과를 피하는 법<br>
  1. 시스템 전체를 벤치마크한다. ( 저수준 수치는 수집하지 않는다.)<br>
  2. 연관된 저수준의 결과를 의미있게 비교하기 위해 앞서 언급한 많은 문제를 공통 프레임워크를 이용해 처리한다.<br>

<h2>JHM 소개</h2>

<h4>휴리스틱:마이크로벤치마킹은 언제 하나?</h4>

마이크로벤치마킹을 하는 주요 유스케이스<br>
 - 사용 범위가 넓은 범용 라이브러리 코드를 개발한다.<br>
 - OpenJDK 또는 다른 자바 플랫폼 구현제를 개발한다.<br>
 - 지연에 극도로 민간한 코드를 개발한다.<br>

=> 마이크로벤치마크는 가장 극단적인 애플리케이션에 한하여 사용하는 것이 좋다<br>

<h4>JHM 프레임워크</h4>
jmh는 자바를 비롯해 jvm을 타깃으로 하는 언어를 적성된 나노/마이크로/밀리/매크로/ 벤치마크를 제작,실행,분석하는 자바 도구이다.<br>
=> jvm릴리즈마다 맞는 jmh도 함께 진화해왔다.<br>

 - 리플렉션을 써서 작성한 벤치마크를 실행하는 우회 방법도 있지만, 벤치마크 실행 경로에 복잡한 jvm 서브 시스템이 하나 더 끼어든다.<br>
 - JMH는 벤치마크 코드에 애너테이션을 붙여 자바 소스를 추가 생성하는 식으로 작동한다.<br>



  
